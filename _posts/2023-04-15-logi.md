---
title:  "로지스틱스 회귀 연습"
excerpt: "로지스틱스 회귀에 대해서 연습해보자"

categories:
  - Blog
tags:
  - [Blog, practice, Github, Git]

toc: true
toc_sticky: true
 
date: 2023-04-15
last_modified_at: 2023-04-16

---

## 로지스틱스 회귀 연습

[kaggle 링크](https://www.kaggle.com/code/prashant111/logistic-regression-classifier-tutorial#Logistic-Regression-Classifier-Tutorial-with-Python)를 토대로 연습해보자

이 연습에서는 호주에 비가 오는지 여부를 예측하기 위해 로지스틱회귀를 이용해 이진분류 모델을 훈련한다

---
## 목차
1. [로지스틱스 회귀 설명/분석 직관](#1.로지스틱스-회귀-설명/분석-직관)
2. [로지스틱스 회귀의 직관](#2.로지스틱스-회귀의-직관)
3. [로지스틱스 회귀의 가정](#3.로지스틱스-회귀의-가정)
4. [로지스티스 회귀의 종류](#4.로지스티스-회귀의-종류)
5. [라이브러리 불러오기](#5.라이브러리-불러오기)
6. [데이터셋 불러오기](#6.데이터셋-불러오기)
7. [데이터 분석 확인](#7.데이터-분석-확인)
8. [특징 벡터 대상 변수 선언](#8.특징-벡터-대상-변수-선언)
9. [데이터를 학습과 테스트 셋으로 분할](#9.데이터를-학습과-테스트-셋으로-분할)
10. [특성 처리](#10.특성-처리)
11. [특성 스케일링](#11.특성-스케일링)
12. [모델 학습](#12.모델-학습)
13. [결과 예측](#13.결과-예측)
14. [정확한 점수 예측](#14.정확한-점수-예측)
15. [혼돈 매트릭스](#15.혼돈-매트릭스)
16. [분류 지표](#16.분류-지표)
17. [임계값 조정](#17.임계값-조정)
18. [ROC-AUC](#18.ROC-AUC)

---
## 1.로지스틱스 회귀 설명/분석 직관

로지스틱 회귀는 데이터 분류에 있어서 가장 기본적인 알고리즘이다.

로지스틱 회귀는 지도학습 분류 알고리즘으로 관측값을 불연속적인 클래스 집합으로 예측하는데 사용된다.

따라서 결과 역시 불연속적이다.

로지스틱 회귀는 분류 문제를 가장 간단하게 해결하게 해주고 다양한 용도로 사용가능하다.

---
## 2.로지스틱스 회귀의 직관

통계학에서 로지스틱 회귀 모델은 분류목적으로 자주 사용된다.

일련의 관측값이 주어지면 로지스틱 회귀 모델을 통해 

관측값을 두 개 이상의 불연속적인 클래스로 분류하는데 도움이 된다.

따라서 대상은 본질적으로 이산형이다.

로지스틱 회귀 알고리즘은 다음과 같이 작동한다.

### 선형 방정식 구현

로지스틱 회귀 알고리즘은 독립 변수 또는 설명 변수로 선형 방정식을 구현하여 응답 값을 예측한다.

예를 들어 공부한 시간과 시험 합격 확률의 예를 살펴 보면, 공부 시간을 변수로 x1이라 하고

시험에 합격할 확률은 응답 또는 목표 변수이며 Z로 표시 된다.

하나의 설명 변수와 결과 변수가 있다면 선형 방정식은 다음과 같은 방정식으로 표현 된다.

```
z = b0 + b1x1
```
여기서 계수 b0, b1은 모델의 매개 변수이다.

변수가 여러개라면 더 확장이된다.

```
z = b0 + b1x1+ b2x2+, ... ,+ bnxn
```
이번에는 b0, b1, b2, .... bn이 모델의 매개 변수이다.

따라서 예측값은 위의 방정식으로 주어진다

### 시그모이드 함수

다음으로는 Z로 표시되는 예측 응답 값을 0과 1사이의 확률 값으로 변환 한다.

그런 다음 이 시그모이드 함수를 이용하여 모든 실제 값을 0과 1사이의 확률 값으로 적용시킨다.


머신 러닝에서 시그모이드 함수는 예측을 확률에 적용하는 데 사용된다.

시그모이드 함수는 S자의 곡선을 가지고 있어 시그모이드 곡선이라고 부르기도 한다.



시그모이드 함수는 로지스틱 함수의 특수한 경우로 다음과 같은 수학 공식으로 표현된다.

$$
Φ(z) = {\frac{1}{1 + e^{-z}}}
$$



그래프로 표현하면 다음과 같다

<img src ="https://miro.medium.com/v2/resize:fit:970/1*Xu7B5y9gp0iL5ooBj7LtWw.png">

### 의사 결정 경계

시그모이드 함수는 0과 1사이의 확률 값의 반환한다.

이 확률 값은 0또는 1인 불연속적인 클래스에 적용된다.

이 확률 값을 불연속적인 클래스(ex 예/아니오)에 적용하기 위해, 임계값을 선택한다.

이 임계값을 의사 결정 경계라고 하며 초과시 확률을 클래스 1에 적용하고  이하라면 클래스 0에 적용한다.


수학적으로는 다음과 같다

```
p≥ 0.5 -> 클래스 = 1

p < 0.5 -> 클래스 = 0

```

일반적으로 의사 결정 경계는 0.5로 설정되는데

따라서 확률값이 0.8일경우 0.5보다 크기때문에 1에 적용된다.

반대로 0.2인 경우 0.5보다 작기 때문에 에 적용된다.

그래프로 표현하면 다음과 같다.

<img src ="https://ml-cheatsheet.readthedocs.io/en/latest/_images/logistic_regression_sigmoid_w_threshold.png">

예측 만들기

이제, 로지스틱 회귀에서 시그모이드 함수와 결정경계에 대해 알게 되었다.

이 두가지를 이용하여 예측 함수를 작성 할 수 있다.

로지스틱 회귀의 예측 함수는 양수일때 참을 반환하고 이를 클래스 1 P(class = 1)이라고 한다.

1에 가까우면 클래스 1에 속하고 그렇지 않으면 클래스 0에 속한다.


---
## 3.로지스틱스 회귀의 가정

로지스틱 회귀 모델에는 몇가지 가정이 필요하다.

1. 로지스틱 회귀 모델은 종속 변수가 이진, 다항식 또는 서수여야 한다.

2. 관측값이 서로 독립적이어야 한다. 따라서 관측값이 반복된 측정값에서 나온것이 아니여야 한다.

3. 독립 변수간에 가중 공선성이 전혀 필요하지 않다. 독립 변수 사이에 높은 상관 관계가 없어야 하기 때문이다.

4. 로지스틱 회귀 모델은 독립 변수와 로그 확률의 선형성을 가진다.

5. 로지스틱 회귀 모델의 성공 여부는 표본 크기에 따라 달라지는데 큰 표본 크기가 유리하다.


---
## 4.로지스티스 회귀의 종류

로지스틱스 회귀 모델은 여러개로 분류할수 있는데, 이는 타겟의 범주에 따라 3가지로 분류 가능하다.

1. 이진 로지스틱스 회귀

이진 로지스틱스 회귀에서는 대상 변수의 범주가 두가지인 경우이다. 

2. 다항 로지스틱스 회귀

다항 로지스틱스 회귀는 대상 변수가 특정 순서가 아닌 세 개 이상의 범주가 있는 경우이다.

3 서수 로지스틱스 회귀

서수 로지스틱스 회귀에는 세 개이상의 서수 범주가 있는 경우로 범주에 내재적인 순서가 존재한다.

---
## 5.라이브러리 불러오기

파이썬 3 환경에는 유용한 분석 라이브러리가 많이 설치되어 있는데

예를 들면 다음과 같은 패키지가 존재한다.

```python
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot as plt # data visualization
import seaborn as sns # statistical data visualization
%matplotlib inline
```

입력 데이터 파일은 "../input/" 디렉토리에서 사용할 수 있다.

```python
import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))        
```
>/input/weather-dataset-rattle-package/weatherAUS.csv

---
## 6.데이터셋 불러오기

```
data = '/kaggle/input/weather-dataset-rattle-package/weatherAUS.csv'

df = pd.read_csv(data)
```

---
## 7.데이터 분석 확인
다음으로 데이터를 탐색하여 데이터에 대한 이해도를 확보한다.

```python
df.shape
```
>(142193, 24)


```
df.head()
```
|Date|Location|MinTem|MaxTemp|Rainfall|Evaporation|Sunshine|WindGustDir|WindGustSpeed|WindDir9am|...|Humidity3pm|Pressure9am|Pressure3pm|Cloud9am|Cloud3pm|Temp9am|Temp3pm|RainToday|RISK_MM|RainTomorrow|
|:---|:---|:---|:---|:---|:---|:---|:---|:---|:---|:---|:---|:---|:---|:---|:---|:---|:---|:---|:---|:---|
|2008-12-01|Albury|13.4|22.9|0.6|NaN|NaN|W|44.0|W|...|22.0|1007.7|1007.1|8.0|NaN|16.9|21.8|No|0.0|No|
|2008-12-02|Albury|7.4|25.1|0.0|NaN|NaN|WNW|44.0|NNW|...|25.0|1010.6|1007.8|NaN|NaN|17.2|24.3|No|0.0|No|
|2008-12-03|Albury|12.9|25.7|0.0|NaN|NaN|WSW|46.0|W|...|30.0|1007.6|1008.7|NaN|2.0|21.0|23.2|No|0.0|No|
|2008-12-04|Albury|9.2|28.0|0.0|NaN|NaN|NE|24.0|SE|...|16.0|1017.6|1012.8|NaN|NaN|18.1|26.5|No|1.0|No|
|2008-12-05|Albury|17.5|32.3|1.0|NaN|NaN|W|41.0|ENE|...|33.0|1010.8|1006.0|7.0|8.0|17.8|29.7|No|0.2|No|


```python
col_names = df.columns

col_names
```

>Index(['Date', 'Location', 'MinTemp', 'MaxTemp', 'Rainfall', 'Evaporation',
       'Sunshine', 'WindGustDir', 'WindGustSpeed', 'WindDir9am', 'WindDir3pm',
       'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', 'Humidity3pm',
       'Pressure9am', 'Pressure3pm', 'Cloud9am', 'Cloud3pm', 'Temp9am',
       'Temp3pm', 'RainToday', 'RISK_MM', 'RainTomorrow'],
      dtype='object')
```python
col_names = df.columns

col_names
```

>Index(['Date', 'Location', 'MinTemp', 'MaxTemp', 'Rainfall', 'Evaporation',
       'Sunshine', 'WindGustDir', 'WindGustSpeed', 'WindDir9am', 'WindDir3pm',
       'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', 'Humidity3pm',
       'Pressure9am', 'Pressure3pm', 'Cloud9am', 'Cloud3pm', 'Temp9am',
       'Temp3pm', 'RainToday', 'RISK_MM', 'RainTomorrow'],
      dtype='object')
      
### RISK MM 특징 삭제
데이터 세트에서 RISK_MM 특징을 삭제해야 한다고 데이터 세트 설명에 존재한다, 따라서 삭제해주도록 한다.

```python
df.drop(['RISK_MM'], axis=1, inplace=True)
df.info()
```

><class 'pandas.core.frame.DataFrame'>
>
>RangeIndex: 142193 entries, 0 to 142192
>
>Data columns (total 23 columns):
>
>Date             142193 non-null object
>
>Location         142193 non-null object
>
>MinTemp          141556 non-null float64
>
>MaxTemp          141871 non-null float64
>
>Rainfall         140787 non-null float64
>
>Evaporation      81350 non-null float64
>
>Sunshine         74377 non-null float64
>
>WindGustDir      132863 non-null object
>
>WindGustSpeed    132923 non-null float64
>
>WindDir9am       132180 non-null object
>
>WindDir3pm       138415 non-null object
>
>WindSpeed9am     140845 non-null float6
>
>WindSpeed3pm     139563 non-null float64
>
>Humidity9am      140419 non-null float64
>
>Humidity3pm      138583 non-null float64
>
>Pressure9am      128179 non-null float64
>
>Pressure3pm      128212 non-null float64
>
>Cloud9am         88536 non-null float64
>
>Cloud3pm         85099 non-null float64
>
>Temp9am          141289 non-null float64
>
>Temp3pm          139467 non-null float64
>
>RainToday        140787 non-null object
>
>RainTomorrow     142193 non-null object
>
>dtypes: float64(16), object(7)
>
>memory usage: 25.0+ MB

### 변수의 유형

```ptython
categorical = [var for var in df.columns if df[var].dtype=='O']

print('There are {} categorical variables\n'.format(len(categorical)))

print('The categorical variables are :', categorical)

```
>There are 7 categorical variables
>
>The categorical variables are : ['Date', 'Location', 'WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday', 'RainTomorrow']

다시 head()로 확인

```python
df[categorical].head()
```
|Date|Location|WindGustDir|WindDir9am|WindDir3pm|RainToday|RainTomorrow|
|:---|:---|:---|:---|:---|:---|:---|
|2008-12-01|Albury|W|W|WNW|No|No|
|2008-12-02|Albury|WNW|NNW|WNW|No|No|
|2008-12-03|Albury|WSW|W|WNW|No|No|
|2008-12-04|Albury|NE|SE|WNW|No|No|
|2008-12-05|Albury|W|ENE|WNW|No|No|


---
## 8.특징 벡터 대상 변수 선언

---
## 9.데이터를 학습과 테스트 셋으로 분할

---
## 10.특성 처리

---
## 11.특성 스케일링

---
## 12.모델 학습

---
## 13.결과 예측

---
## 14.정확한 점수 예측

---
## 15.혼돈 매트릭스

---
## 16.분류 지표

---
## 17.임계값 조정

---
## 18.ROC-AUC


