---
title:  "로지스틱스 회귀 연습"
excerpt: "로지스틱스 회귀에 대해서 연습해보자"

categories:
  - Blog
tags:
  - [Blog, practice, Github, Git]

toc: true
toc_sticky: true
 
date: 2023-04-14
last_modified_at: 2023-04-14

---

## 로지스틱스 회귀 연습

[kaggle 링크](https://www.kaggle.com/code/prashant111/logistic-regression-classifier-tutorial#Logistic-Regression-Classifier-Tutorial-with-Python)를 토대로 연습해보자

이 연습에서는 호주에 비가 오는지 여부를 예측하기 위해 로지스틱회귀를 이용해 이진분류 모델을 훈련한다

---


## 목차
[1. 로지스틱스 회귀 설명](#1로지스틱스-회귀-설명)

[2. 로지스틱스 회귀의 직관](#2로지스틱스-회귀의-직관)

[3. 로지스틱스 회귀의 가정](#3로지스틱스-회귀의-가정)

[4. 로지스티스 회귀의 종류](#4로지스티스-회귀의-종류)

[5. 라이브러리 불러오기](#5라이브러리-불러오기)

[6. 데이터셋 불러오기](#6데이터셋-불러오기)

[7. 데이터 분석 확인](#7데이터-분석-확인)

[8. 특징 벡터 대상 변수 선언](#8특징-벡터-대상-변수-선언)

[9. 데이터를 학습과 테스트 셋으로 분할](#9데이터를-학습과-테스트-셋으로-분할)

[10. 특성 처리](#10특성-처리)

[11. 특성 스케일링](#11특성-스케일링)

[12. 모델 학습](#12모델-학습)

[13. 결과 예측](#13결과-예측)

[14. 정확한 점수 예측](#14정확한-점수-예측)

[15. 혼돈 행렬](#15혼돈-행렬)

[16. 분류 지표](#16분류-지표)

[17. 임계값 조정](#17임계값-조정)

[18. ROC-AUC](#18roc-auc)

[19.k폴드 교차 검증](#19k폴드-교차-검증)

[20.그리드탐색을 이용한 하이퍼파라미터](#20그리드탐색을-이용한-하이퍼파라미터)

[21.결과 및 결론](#21결과-및-결론)



---
## 1.로지스틱스 회귀 설명

로지스틱 회귀는 데이터 분류에 있어서 가장 기본적인 알고리즘이다.

로지스틱 회귀는 지도학습 분류 알고리즘으로 관측값을 불연속적인 클래스 집합으로 예측하는데 사용된다.

따라서 결과 역시 불연속적이다.

로지스틱 회귀는 분류 문제를 가장 간단하게 해결하게 해주고 다양한 용도로 사용가능하다.

---
## 2.로지스틱스 회귀의 직관

통계학에서 로지스틱 회귀 모델은 분류목적으로 자주 사용된다.

일련의 관측값이 주어지면 로지스틱 회귀 모델을 통해 

관측값을 두 개 이상의 불연속적인 클래스로 분류하는데 도움이 된다.

따라서 대상은 본질적으로 이산형이다.

로지스틱 회귀 알고리즘은 다음과 같이 작동한다.

### 선형 방정식 구현

로지스틱 회귀 알고리즘은 독립 변수 또는 설명 변수로 선형 방정식을 구현하여 응답 값을 예측한다.

예를 들어 공부한 시간과 시험 합격 확률의 예를 살펴 보면, 공부 시간을 변수로 x1이라 하고

시험에 합격할 확률은 응답 또는 목표 변수이며 Z로 표시 된다.

하나의 설명 변수와 결과 변수가 있다면 선형 방정식은 다음과 같은 방정식으로 표현 된다.

```
z = b0 + b1x1
```
여기서 계수 b0, b1은 모델의 매개 변수이다.

변수가 여러개라면 더 확장이된다.

```
z = b0 + b1x1+ b2x2+, ... ,+ bnxn
```
이번에는 b0, b1, b2, .... bn이 모델의 매개 변수이다.

따라서 예측값은 위의 방정식으로 주어진다

### 시그모이드 함수

다음으로는 Z로 표시되는 예측 응답 값을 0과 1사이의 확률 값으로 변환 한다.

그런 다음 이 시그모이드 함수를 이용하여 모든 실제 값을 0과 1사이의 확률 값으로 적용시킨다.


머신 러닝에서 시그모이드 함수는 예측을 확률에 적용하는 데 사용된다.

시그모이드 함수는 S자의 곡선을 가지고 있어 시그모이드 곡선이라고 부르기도 한다.



시그모이드 함수는 로지스틱 함수의 특수한 경우로 다음과 같은 수학 공식으로 표현된다.

$$
Φ(z) = {\frac{1}{1 + e^{-z}}}
$$



그래프로 표현하면 다음과 같다

<img src ="https://miro.medium.com/v2/resize:fit:970/1*Xu7B5y9gp0iL5ooBj7LtWw.png">

### 의사 결정 경계

시그모이드 함수는 0과 1사이의 확률 값의 반환한다.

이 확률 값은 0또는 1인 불연속적인 클래스에 적용된다.

이 확률 값을 불연속적인 클래스(ex 예/아니오)에 적용하기 위해, 임계값을 선택한다.

이 임계값을 의사 결정 경계라고 하며 초과시 확률을 클래스 1에 적용하고  이하라면 클래스 0에 적용한다.


수학적으로는 다음과 같다

```
p≥ 0.5 -> 클래스 = 1

p < 0.5 -> 클래스 = 0

```

일반적으로 의사 결정 경계는 0.5로 설정되는데

따라서 확률값이 0.8일경우 0.5보다 크기때문에 1에 적용된다.

반대로 0.2인 경우 0.5보다 작기 때문에 에 적용된다.

그래프로 표현하면 다음과 같다.

<img src ="https://ml-cheatsheet.readthedocs.io/en/latest/_images/logistic_regression_sigmoid_w_threshold.png">

예측 만들기

이제, 로지스틱 회귀에서 시그모이드 함수와 결정경계에 대해 알게 되었다.

이 두가지를 이용하여 예측 함수를 작성 할 수 있다.

로지스틱 회귀의 예측 함수는 양수일때 참을 반환하고 이를 클래스 1 P(class = 1)이라고 한다.

1에 가까우면 클래스 1에 속하고 그렇지 않으면 클래스 0에 속한다.


---
## 3.로지스틱스 회귀의 가정

로지스틱 회귀 모델에는 몇가지 가정이 필요하다.

1. 로지스틱 회귀 모델은 종속 변수가 이진, 다항식 또는 서수여야 한다.

2. 관측값이 서로 독립적이어야 한다. 따라서 관측값이 반복된 측정값에서 나온것이 아니여야 한다.

3. 독립 변수간에 가중 공선성이 전혀 필요하지 않다. 독립 변수 사이에 높은 상관 관계가 없어야 하기 때문이다.

4. 로지스틱 회귀 모델은 독립 변수와 로그 확률의 선형성을 가진다.

5. 로지스틱 회귀 모델의 성공 여부는 표본 크기에 따라 달라지는데 큰 표본 크기가 유리하다.


---
## 4.로지스티스 회귀의 종류

로지스틱스 회귀 모델은 여러개로 분류할수 있는데, 이는 타겟의 범주에 따라 3가지로 분류 가능하다.

1. 이진 로지스틱스 회귀

이진 로지스틱스 회귀에서는 대상 변수의 범주가 두가지인 경우이다. 

2. 다항 로지스틱스 회귀

다항 로지스틱스 회귀는 대상 변수가 특정 순서가 아닌 세 개 이상의 범주가 있는 경우이다.

3 서수 로지스틱스 회귀

서수 로지스틱스 회귀에는 세 개이상의 서수 범주가 있는 경우로 범주에 내재적인 순서가 존재한다.

---
## 5.라이브러리 불러오기

파이썬 3 환경에는 유용한 분석 라이브러리가 많이 설치되어 있는데

예를 들면 다음과 같은 패키지가 존재한다.

```python
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot as plt # data visualization
import seaborn as sns # statistical data visualization
%matplotlib inline
```

입력 데이터 파일은 "../input/" 디렉토리에서 사용할 수 있다.

```python
import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))        
```
>/input/weather-dataset-rattle-package/weatherAUS.csv

---
## 6.데이터셋 불러오기

```
data = '/kaggle/input/weather-dataset-rattle-package/weatherAUS.csv'

df = pd.read_csv(data)
```

---
## 7.데이터 분석 확인
다음으로 데이터를 탐색하여 데이터에 대한 이해도를 확보한다.

```python
df.shape
```
>(142193, 24)


```
df.head()
```

<div class="scroll">

|Date|Location|MinTem|MaxTemp|Rainfall|Evaporation|Sunshine|WindGustDir|WindGustSpeed|WindDir9am|...|Humidity3pm|Pressure9am|Pressure3pm|Cloud9am|Cloud3pm|Temp9am|Temp3pm|RainToday|RISK_MM|RainTomorrow|
|:---|:---|:---|:---|:---|:---|:---|:---|:---|:---|:---|:---|:---|:---|:---|:---|:---|:---|:---|:---|:---|
|2008-12-01|Albury|13.4|22.9|0.6|NaN|NaN|W|44.0|W|...|22.0|1007.7|1007.1|8.0|NaN|16.9|21.8|No|0.0|No|
|2008-12-02|Albury|7.4|25.1|0.0|NaN|NaN|WNW|44.0|NNW|...|25.0|1010.6|1007.8|NaN|NaN|17.2|24.3|No|0.0|No|
|2008-12-03|Albury|12.9|25.7|0.0|NaN|NaN|WSW|46.0|W|...|30.0|1007.6|1008.7|NaN|2.0|21.0|23.2|No|0.0|No|
|2008-12-04|Albury|9.2|28.0|0.0|NaN|NaN|NE|24.0|SE|...|16.0|1017.6|1012.8|NaN|NaN|18.1|26.5|No|1.0|No|
|2008-12-05|Albury|17.5|32.3|1.0|NaN|NaN|W|41.0|ENE|...|33.0|1010.8|1006.0|7.0|8.0|17.8|29.7|No|0.2|No|

<\div>
  
  
```python
col_names = df.columns

col_names
```

>Index(['Date', 'Location', 'MinTemp', 'MaxTemp', 'Rainfall', 'Evaporation',
       'Sunshine', 'WindGustDir', 'WindGustSpeed', 'WindDir9am', 'WindDir3pm',
       'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', 'Humidity3pm',
       'Pressure9am', 'Pressure3pm', 'Cloud9am', 'Cloud3pm', 'Temp9am',
       'Temp3pm', 'RainToday', 'RISK_MM', 'RainTomorrow'],
      dtype='object')
```python
col_names = df.columns

col_names
```

>Index(['Date', 'Location', 'MinTemp', 'MaxTemp', 'Rainfall', 'Evaporation',
       'Sunshine', 'WindGustDir', 'WindGustSpeed', 'WindDir9am', 'WindDir3pm',
       'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', 'Humidity3pm',
       'Pressure9am', 'Pressure3pm', 'Cloud9am', 'Cloud3pm', 'Temp9am',
       'Temp3pm', 'RainToday', 'RISK_MM', 'RainTomorrow'],
      dtype='object')
      
### RISK MM 특징 삭제
데이터 세트에서 RISK_MM 특징을 삭제해야 한다고 데이터 세트 설명에 존재한다, 따라서 삭제해주도록 한다.

```python
df.drop(['RISK_MM'], axis=1, inplace=True)
df.info()
```

><class 'pandas.core.frame.DataFrame'>
>
>RangeIndex: 142193 entries, 0 to 142192
>
>Data columns (total 23 columns):
>
>Date             142193 non-null object
>
>Location         142193 non-null object
>
>MinTemp          141556 non-null float64
>
>MaxTemp          141871 non-null float64
>
>Rainfall         140787 non-null float64
>
>Evaporation      81350 non-null float64
>
>Sunshine         74377 non-null float64
>
>WindGustDir      132863 non-null object
>
>WindGustSpeed    132923 non-null float64
>
>WindDir9am       132180 non-null object
>
>WindDir3pm       138415 non-null object
>
>WindSpeed9am     140845 non-null float6
>
>WindSpeed3pm     139563 non-null float64
>
>Humidity9am      140419 non-null float64
>
>Humidity3pm      138583 non-null float64
>
>Pressure9am      128179 non-null float64
>
>Pressure3pm      128212 non-null float64
>
>Cloud9am         88536 non-null float64
>
>Cloud3pm         85099 non-null float64
>
>Temp9am          141289 non-null float64
>
>Temp3pm          139467 non-null float64
>
>RainToday        140787 non-null object
>
>RainTomorrow     142193 non-null object
>
>dtypes: float64(16), object(7)
>
>memory usage: 25.0+ MB

### 변수의 유형

```ptython
categorical = [var for var in df.columns if df[var].dtype=='O']

print('There are {} categorical variables\n'.format(len(categorical)))

print('The categorical variables are :', categorical)

```
>There are 7 categorical variables
>
>The categorical variables are : ['Date', 'Location', 'WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday', 'RainTomorrow']

다시 head()로 확인

```python
df[categorical].head()
```


|Date|Location|WindGustDir|WindDir9am|WindDir3pm|RainToday|RainTomorrow|
|:---|:---|:---|:---|:---|:---|:---|
|2008-12-01|Albury|W|W|WNW|No|No|
|2008-12-02|Albury|WNW|NNW|WNW|No|No|
|2008-12-03|Albury|WSW|W|WNW|No|No|
|2008-12-04|Albury|NE|SE|WNW|No|No|
|2008-12-05|Albury|W|ENE|WNW|No|No|



### 범주형 변수를 요약하면 다음과 같다

 * 날짜 변수 - Date
 * 6개의 범주형 변수 - Location, WindGustDir, WindDir9am, WindDir3pm, RainToday, RainTomorrow
 * 이진 범주형 변수- RainToday, RainTomorrow
 * 대상 변수 - RainTomorrow


### 범주현 변수의 문제 탐색

결측치를 찾아준다.
```python
df[categorical].isnull().sum()
```
>Date                0
>
>Location            0
>
>WindGustDir      9330
>
>WindDir9am      10013
>
>WindDir3pm       3778
>
>RainToday        1406
>
>RainTomorrow        0
>
>dtype: int64

결측치가 포함된 범주형 변수만 프린트한다.
```python
cat1 = [var for var in categorical if df[var].isnull().sum()!=0]
print(df[cat1].isnull().sum())
```
>WindGustDir     9330
>
>WindDir9am     10013
>
>WindDir3pm      3778
>
>RainToday       1406
>
>dtype: int64

4개의 범주형 변수만이 결측치가 존재함을 확인했다.

WindGustDir, WindDir9am, WindDir3pm, RainToday 에 결측치가 존재한다.

### 범주형 변수의 빈도 수

다음으로 범주형 변수의 빈도 수를 확인한다.
```python
for var in categorical: 
    
    print(df[var].value_counts())
```
```
2014-04-15    49
2013-08-04    49
2014-03-18    49
2014-07-08    49
2014-02-27    49
              ..
2007-11-01     1
2007-12-30     1
2007-12-12     1
2008-01-20     1
2007-12-05     1
Name: Date, Length: 3436, dtype: int64
Canberra            3418
Sydney              3337
Perth               3193
Darwin              3192
Hobart              3188
Brisbane            3161
Adelaide            3090
Bendigo             3034
Townsville          3033
AliceSprings        3031
MountGambier        3030
Ballarat            3028
Launceston          3028
Albany              3016
Albury              3011
PerthAirport        3009
MelbourneAirport    3009
Mildura             3007
SydneyAirport       3005
Nuriootpa           3002
Sale                3000
Watsonia            2999
Tuggeranong         2998
Portland            2996
Woomera             2990
Cobar               2988
Cairns              2988
Wollongong          2983
GoldCoast           2980
WaggaWagga          2976
NorfolkIsland       2964
Penrith             2964
SalmonGums          2955
Newcastle           2955
CoffsHarbour        2953
Witchcliffe         2952
Richmond            2951
Dartmoor            2943
NorahHead           2929
BadgerysCreek       2928
MountGinini         2907
Moree               2854
Walpole             2819
PearceRAAF          2762
Williamtown         2553
Melbourne           2435
Nhil                1569
Katherine           1559
Uluru               1521
Name: Location, dtype: int64
W      9780
SE     9309
E      9071
N      9033
SSE    8993
S      8949
WSW    8901
SW     8797
SSW    8610
WNW    8066
NW     8003
ENE    7992
ESE    7305
NE     7060
NNW    6561
NNE    6433
Name: WindGustDir, dtype: int64
N      11393
SE      9162
E       9024
SSE     8966
NW      8552
S       8493
W       8260
SW      8237
NNE     7948
NNW     7840
ENE     7735
ESE     7558
NE      7527
SSW     7448
WNW     7194
WSW     6843
Name: WindDir9am, dtype: int64
SE     10663
W       9911
S       9598
WSW     9329
SW      9182
SSE     9142
N       8667
WNW     8656
NW      8468
ESE     8382
E       8342
NE      8164
SSW     8010
NNW     7733
ENE     7724
NNE     6444
Name: WindDir3pm, dtype: int64
No     109332
Yes     31455
Name: RainToday, dtype: int64
No     110316
Yes     31877
Name: RainTomorrow, dtype: int64
```
```python
for var in categorical: 
    
    print(df[var].value_counts()/np.float(len(df)))
```
범주형 변수의 빈도 분포 확인
```
2014-04-15    0.000345
2013-08-04    0.000345
2014-03-18    0.000345
2014-07-08    0.000345
2014-02-27    0.000345
                ...   
2007-11-01    0.000007
2007-12-30    0.000007
2007-12-12    0.000007
2008-01-20    0.000007
2007-12-05    0.000007
Name: Date, Length: 3436, dtype: float64
Canberra            0.024038
Sydney              0.023468
Perth               0.022455
Darwin              0.022448
Hobart              0.022420
Brisbane            0.022230
Adelaide            0.021731
Bendigo             0.021337
Townsville          0.021330
AliceSprings        0.021316
MountGambier        0.021309
Ballarat            0.021295
Launceston          0.021295
Albany              0.021211
Albury              0.021175
PerthAirport        0.021161
MelbourneAirport    0.021161
Mildura             0.021147
SydneyAirport       0.021133
Nuriootpa           0.021112
Sale                0.021098
Watsonia            0.021091
Tuggeranong         0.021084
Portland            0.021070
Woomera             0.021028
Cobar               0.021014
Cairns              0.021014
Wollongong          0.020979
GoldCoast           0.020957
WaggaWagga          0.020929
NorfolkIsland       0.020845
Penrith             0.020845
SalmonGums          0.020782
Newcastle           0.020782
CoffsHarbour        0.020768
Witchcliffe         0.020761
Richmond            0.020753
Dartmoor            0.020697
NorahHead           0.020599
BadgerysCreek       0.020592
MountGinini         0.020444
Moree               0.020071
Walpole             0.019825
PearceRAAF          0.019424
Williamtown         0.017954
Melbourne           0.017125
Nhil                0.011034
Katherine           0.010964
Uluru               0.010697
Name: Location, dtype: float64
W      0.068780
SE     0.065467
E      0.063794
N      0.063526
SSE    0.063245
S      0.062936
WSW    0.062598
SW     0.061867
SSW    0.060552
WNW    0.056726
NW     0.056283
ENE    0.056205
ESE    0.051374
NE     0.049651
NNW    0.046142
NNE    0.045241
Name: WindGustDir, dtype: float64
N      0.080123
SE     0.064434
E      0.063463
SSE    0.063055
NW     0.060144
S      0.059729
W      0.058090
SW     0.057928
NNE    0.055896
NNW    0.055136
ENE    0.054398
ESE    0.053153
NE     0.052935
SSW    0.052380
WNW    0.050593
WSW    0.048125
Name: WindDir9am, dtype: float64
SE     0.074990
W      0.069701
S      0.067500
WSW    0.065608
SW     0.064574
SSE    0.064293
N      0.060952
WNW    0.060875
NW     0.059553
ESE    0.058948
E      0.058667
NE     0.057415
SSW    0.056332
NNW    0.054384
ENE    0.054321
NNE    0.045319
Name: WindDir3pm, dtype: float64
No     0.768899
Yes    0.221213
Name: RainToday, dtype: float64
No     0.775819
Yes    0.224181
Name: RainTomorrow, dtype: float64
```
### 레이블 수 : 카디널리티
범주형 변수내의 레이블 수를 카디널리티라고 한다

변수내의 레이블 수가 많으면 높은 카디널리티라고 하는데

이는 머신 러닝 모델에서 문제를 일으킬 수 있기 때문에 한번 확인해본다.

```python
for var in categorical:
    
    print(var, ' contains ', len(df[var].unique()), ' labels')
```
```
Date  contains  3436  labels
Location  contains  49  labels
WindGustDir  contains  17  labels
WindDir9am  contains  17  labels
WindDir3pm  contains  17  labels
RainToday  contains  3  labels
RainTomorrow  contains  2  labels
```

Date에 변수가 많아, 전처리가 필요함을 알 수 있다



### 날짜 변수의 특성 전처리

```
df['Date'].dtypes
```
> dtype('O')

Date의 타입이 오브젝트임을 확인했다.

Date를 날짜와 시간 형식으로 구문을 분석한다

```python
df['Date'] = pd.to_datetime(df['Date'])
```

해를 먼저 추출

```python
df['Year'] = df['Date'].dt.year
df['Year'].head()
```
```
0    2008
1    2008
2    2008
3    2008
4    2008
Name: Year, dtype: int64
```
다음으로는 월을 추출한다

```python
df['Month'] = df['Date'].dt.month

df['Month'].head()
```
```
0    12
1    12
2    12
3    12
4    12
Name: Month, dtype: int64
```

마지막으로 일을 추출해준다
```python
f['Day'] = df['Date'].dt.day

df['Day'].head()
```

```
0    1
1    2
2    3
3    4
4    5
Name: Day, dtype: int64
```

다시 데이터 셋의 요약을 확인한다
```python
df.info()
```

```
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 142193 entries, 0 to 142192
Data columns (total 26 columns):
Date             142193 non-null datetime64[ns]
Location         142193 non-null object
MinTemp          141556 non-null float64
MaxTemp          141871 non-null float64
Rainfall         140787 non-null float64
Evaporation      81350 non-null float64
Sunshine         74377 non-null float64
WindGustDir      132863 non-null object
WindGustSpeed    132923 non-null float64
WindDir9am       132180 non-null object
WindDir3pm       138415 non-null object
WindSpeed9am     140845 non-null float64
WindSpeed3pm     139563 non-null float64
Humidity9am      140419 non-null float64
Humidity3pm      138583 non-null float64
Pressure9am      128179 non-null float64
Pressure3pm      128212 non-null float64
Cloud9am         88536 non-null float64
Cloud3pm         85099 non-null float64
Temp9am          141289 non-null float64
Temp3pm          139467 non-null float64
RainToday        140787 non-null object
RainTomorrow     142193 non-null object
Year             142193 non-null int64
Month            142193 non-null int64
Day              142193 non-null int64
dtypes: datetime64[ns](1), float64(16), int64(3), object(6)
memory usage: 28.2+ MB
```
Date 변수로부터 세개의 열이 추가된것을 알 수 있다.

이제 원래 Date를 삭제해준다.

```python
df.drop('Date', axis=1, inplace = True)
```

```python
df.head()
```


|Location|MinTemp|MaxTemp|Rainfall|Evaporation|Sunshine|WindGustDir|WindGustSpeed|WindDir9am|WindDir3pm|...|Pressure3pm|Cloud9am|Cloud3pm|Temp9am|Temp3pm|RainToday|RainTomorrow|Year|Month|Day|
|:---|:---|:---|:---|:---|:---|:---|:---|:---|:---|:---|:---|:---|:---|:---|:---|:---|:---|:---|:---|:---|
|Albury|13.4|22.9|0.6|NaN|NaN|W|44.0|W|WNW|...|1007.1|8.0|NaN|16.9|21.8|No|No|2008|12|1|
|Albury|7.4|25.1|0.0|NaN|NaN|WNW|44.0|NNW|WsW|...|1007.2|NaN|NaN|17.2|24.3|No|No|2008|12|2|
|Albury|12.9|25.7|0.0|NaN|NaN|WSW|46.0|W|WsW|...|1008.7|NaN|2.0|21.0|23.2|No|No|2008|12|3|
|Albury|9.2|28|0.0|NaN|NaN|NE|24.0|SE|E|...|1012.8|NaN|NaN|18.1|26.5|No|No|2008|12|4|
|Albury|17.5|32.3|0.0|NaN|NaN|W|41.0|EBE|NW|...|1006.0|7.0|8.0|17.8|29.7|No|No|2008|12|5|



Date가 삭제되고 연,월,일이 추가된것을 확인할 수 있다.

### 범주형 변수 탐색

이번에는 각각의 범주형 변수를 한개씩 살펴본다
```python

categorical = [var for var in df.columns if df[var].dtype=='O']

print('There are {} categorical variables\n'.format(len(categorical)))

print('The categorical variables are :', categorical)
```
```
There are 6 categorical variables

The categorical variables are : ['Location', 'WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday', 'RainTomorrow']
```
데이터 셋에 6개의 범주형 변수가 있음을 확인할 수 있다.

이제 범주현 변수의 결측치를 확인한다.

```python
df[categorical].isnull().sum()
```
```
Location            0
WindGustDir      9330
WindDir9am      10013
WindDir3pm       3778
RainToday        1406
RainTomorrow        0
dtype: int64
```

WindGustDir, WindDir9am, WindDir3pm, RainToday 이 변수들에 결측치가 존재함을 확인할수 있다.

### Location 탐색하기

```python
print('Location contains', len(df.Location.unique()), 'labels')
```
>Location contains 49 labels

```python
df.Location.unique()
```

```
array(['Albury', 'BadgerysCreek', 'Cobar', 'CoffsHarbour', 'Moree',
       'Newcastle', 'NorahHead', 'NorfolkIsland', 'Penrith', 'Richmond',
       'Sydney', 'SydneyAirport', 'WaggaWagga', 'Williamtown',
       'Wollongong', 'Canberra', 'Tuggeranong', 'MountGinini', 'Ballarat',
       'Bendigo', 'Sale', 'MelbourneAirport', 'Melbourne', 'Mildura',
       'Nhil', 'Portland', 'Watsonia', 'Dartmoor', 'Brisbane', 'Cairns',
       'GoldCoast', 'Townsville', 'Adelaide', 'MountGambier', 'Nuriootpa',
       'Woomera', 'Albany', 'Witchcliffe', 'PearceRAAF', 'PerthAirport',
       'Perth', 'SalmonGums', 'Walpole', 'Hobart', 'Launceston',
       'AliceSprings', 'Darwin', 'Katherine', 'Uluru'], dtype=object)
```
이번에는 Locarion의 값의 분포를 확인한다

```python
df.Location.value_counts()
```
```
Canberra            3418
Sydney              3337
Perth               3193
Darwin              3192
Hobart              3188
Brisbane            3161
Adelaide            3090
Bendigo             3034
Townsville          3033
AliceSprings        3031
MountGambier        3030
Ballarat            3028
Launceston          3028
Albany              3016
Albury              3011
PerthAirport        3009
MelbourneAirport    3009
Mildura             3007
SydneyAirport       3005
Nuriootpa           3002
Sale                3000
Watsonia            2999
Tuggeranong         2998
Portland            2996
Woomera             2990
Cobar               2988
Cairns              2988
Wollongong          2983
GoldCoast           2980
WaggaWagga          2976
NorfolkIsland       2964
Penrith             2964
SalmonGums          2955
Newcastle           2955
CoffsHarbour        2953
Witchcliffe         2952
Richmond            2951
Dartmoor            2943
NorahHead           2929
BadgerysCreek       2928
MountGinini         2907
Moree               2854
Walpole             2819
PearceRAAF          2762
Williamtown         2553
Melbourne           2435
Nhil                1569
Katherine           1559
Uluru               1521
Name: Location, dtype: int64
```
이제는 원-핫 인코딩을 통해 Location을 전처리 해준다
```python
pd.get_dummies(df.Location, drop_first=True).head()
```


 	
  
  |Albany|Albury|AliceSprings|BadgerysCreek|Ballarat|Bendigo|Brisbane|Cairns|Canberra|Cobar|...|Townsville|Tuggeranong|Uluru|WaggaWagga|Walpole|Watsonia|Williamtown|Witchcliffe|Wollongong|Woomera|
|---:|---:|---:|---:|---:|---:|---:|---:|---:|---:|---:|---:|---:|---:|---:|---:|---:|---:|---:|---:|---:|
|0|1|0|0|0|0|0|0|0|0|...|0|0|0|0|0|0|0|0|0|0|
|0|1|0|0|0|0|0|0|0|0|...|0|0|0|0|0|0|0|0|0|0|
|0|1|0|0|0|0|0|0|0|0|...|0|0|0|0|0|0|0|0|0|0|
|0|1|0|0|0|0|0|0|0|0|...|0|0|0|0|0|0|0|0|0|0|
|0|1|0|0|0|0|0|0|0|0|...|0|0|0|0|0|0|0|0|0|0|

### WIndGustDir 탐색하기

WindGustDir의 레이블을 탐색한다

```python
print('WindGustDir contains', len(df['WindGustDir'].unique()), 'labels')
```
>WindGustDir contains 17 labels

```python
df['WindGustDir'].unique()
```
```
array(['W', 'WNW', 'WSW', 'NE', 'NNW', 'N', 'NNE', 'SW', 'ENE', 'SSE',
       'S', 'NW', 'SE', 'ESE', nan, 'E', 'SSW'], dtype=object)
```

```python
df.WindGustDir.value_counts()
```
```
W      9780
SE     9309
E      9071
N      9033
SSE    8993
S      8949
WSW    8901
SW     8797
SSW    8610
WNW    8066
NW     8003
ENE    7992
ESE    7305
NE     7060
NNW    6561
NNE    6433
Name: WindGustDir, dtype: int64
```
또 원핫 인코딩 해준다
```python
pd.get_dummies(df.WindGustDir, drop_first=True, dummy_na=True)
```

```python
pd.get_dummies(df.WindGustDir, drop_first=True, dummy_na=True).sum(axis=0)
```
```
ENE    7992
ESE    7305
N      9033
NE     7060
NNE    6433
NNW    6561
NW     8003
S      8949
SE     9309
SSE    8993
SSW    8610
SW     8797
W      9780
WNW    8066
WSW    8901
NaN    9330
dtype: int64
```

### WindDir9am 탐색하기
```python
print('WindDir9am contains', len(df['WindDir9am'].unique()), 'labels')
```
>WindDir9am contains 17 labels

unique로 확인.

```python
df['WindDir9am'].unique()
```
```
array(['W', 'NNW', 'SE', 'ENE', 'SW', 'SSE', 'S', 'NE', nan, 'SSW', 'N',
       'WSW', 'ESE', 'E', 'NW', 'WNW', 'NNE'], dtype=object)
```
이제는 값을 확인해준다.

```python
df['WindDir9am'].value_counts()
```
```
N      11393
SE      9162
E       9024
SSE     8966
NW      8552
S       8493
W       8260
SW      8237
NNE     7948
NNW     7840
ENE     7735
ESE     7558
NE      7527
SSW     7448
WNW     7194
WSW     6843
Name: WindDir9am, dtype: int64
```
역시 원 핫 인코딩
```python
pd.get_dummies(df.WindDir9am, drop_first=True, dummy_na=True)
```
```python
pd.get_dummies(df.WindDir9am, drop_first=True, dummy_na=True).sum(axis=0)
```
```
ENE     7735
ESE     7558
N      11393
NE      7527
NNE     7948
NNW     7840
NW      8552
S       8493
SE      9162
SSE     8966
SSW     7448
SW      8237
W       8260
WNW     7194
WSW     6843
NaN    10013
dtype: int64
```

10013개의 결측치가 있는것도 확인했다.

이외에 다른 변수들도 원-핫 인코딩 해준다

### WindDir3pm

```python
pd.get_dummies(df.WindDir3pm, drop_first=True, dummy_na=True).sum(axis=0)
```
```
ENE     7724
ESE     8382
N       8667
NE      8164
NNE     6444
NNW     7733
NW      8468
S       9598
SE     10663
SSE     9142
SSW     8010
SW      9182
W       9911
WNW     8656
WSW     9329
NaN     3778
dtype: int64
```

### RainToday
```python
pd.get_dummies(df.RainToday, drop_first=True, dummy_na=True).sum(axis=0)
```
```
Yes    31455
NaN     1406
dtype: int64
```
### 수치형 데이터를 탐색

이번에는 수치형 데이터들을 탐색해준다

```python

numerical = [var for var in df.columns if df[var].dtype!='O']

print('There are {} numerical variables\n'.format(len(numerical)))

print('The numerical variables are :', numerical)
```
```
There are 19 numerical variables

The numerical variables are : ['MinTemp', 'MaxTemp', 'Rainfall', 'Evaporation', 'Sunshine', 'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', 'Humidity3pm', 'Pressure9am', 'Pressure3pm', 'Cloud9am', 'Cloud3pm', 'Temp9am', 'Temp3pm', 'Year', 'Month', 'Day']
```
```python
df[numerical].head()
```


<div>

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>MinTemp</th>
      <th>MaxTemp</th>
      <th>Rainfall</th>
      <th>Evaporation</th>
      <th>Sunshine</th>
      <th>WindGustSpeed</th>
      <th>WindSpeed9am</th>
      <th>WindSpeed3pm</th>
      <th>Humidity9am</th>
      <th>Humidity3pm</th>
      <th>Pressure9am</th>
      <th>Pressure3pm</th>
      <th>Cloud9am</th>
      <th>Cloud3pm</th>
      <th>Temp9am</th>
      <th>Temp3pm</th>
      <th>Year</th>
      <th>Month</th>
      <th>Day</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>13.4</td>
      <td>22.9</td>
      <td>0.6</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>44.0</td>
      <td>20.0</td>
      <td>24.0</td>
      <td>71.0</td>
      <td>22.0</td>
      <td>1007.7</td>
      <td>1007.1</td>
      <td>8.0</td>
      <td>NaN</td>
      <td>16.9</td>
      <td>21.8</td>
      <td>2008</td>
      <td>12</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>7.4</td>
      <td>25.1</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>44.0</td>
      <td>4.0</td>
      <td>22.0</td>
      <td>44.0</td>
      <td>25.0</td>
      <td>1010.6</td>
      <td>1007.8</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>17.2</td>
      <td>24.3</td>
      <td>2008</td>
      <td>12</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>12.9</td>
      <td>25.7</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>46.0</td>
      <td>19.0</td>
      <td>26.0</td>
      <td>38.0</td>
      <td>30.0</td>
      <td>1007.6</td>
      <td>1008.7</td>
      <td>NaN</td>
      <td>2.0</td>
      <td>21.0</td>
      <td>23.2</td>
      <td>2008</td>
      <td>12</td>
      <td>3</td>
    </tr>
    <tr>
      <th>3</th>
      <td>9.2</td>
      <td>28.0</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>24.0</td>
      <td>11.0</td>
      <td>9.0</td>
      <td>45.0</td>
      <td>16.0</td>
      <td>1017.6</td>
      <td>1012.8</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>18.1</td>
      <td>26.5</td>
      <td>2008</td>
      <td>12</td>
      <td>4</td>
    </tr>
    <tr>
      <th>4</th>
      <td>17.5</td>
      <td>32.3</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>41.0</td>
      <td>7.0</td>
      <td>20.0</td>
      <td>82.0</td>
      <td>33.0</td>
      <td>1010.8</td>
      <td>1006.0</td>
      <td>7.0</td>
      <td>8.0</td>
      <td>17.8</td>
      <td>29.7</td>
      <td>2008</td>
      <td>12</td>
      <td>5</td>
    </tr>
  </tbody>
</table>
</div>

### 수치형 변수들을 요약하면 다음과 같다
 * 16개의 수치형 변수 존재.
 * MinTemp, MaxTemp, Rainfall, Evaporation, Sunshine, WindGustSpeed, WindSpeed9am, WindSpeed3pm, Humidity9am, Humidity3pm, Pressure9am, Pressure3pm, Cloud9am, Cloud3pm, Temp9am and Temp3pm는 수치형 변수이다.
 * 모든 수치형 변수는 연속형이다.

### 수치형 변수의 문제점 확인

```python
df[numerical].isnull().sum()
```
```
MinTemp            637
MaxTemp            322
Rainfall          1406
Evaporation      60843
Sunshine         67816
WindGustSpeed     9270
WindSpeed9am      1348
WindSpeed3pm      2630
Humidity9am       1774
Humidity3pm       3610
Pressure9am      14014
Pressure3pm      13981
Cloud9am         53657
Cloud3pm         57094
Temp9am            904
Temp3pm           2726
Year                 0
Month                0
Day                  0
dtype: int64
```
모두 결측치가 존재함을 확인했다

### 수치형 변수의 이상치
```python
print(round(df[numerical].describe()),2)
```
```
        MinTemp   MaxTemp  Rainfall  Evaporation  Sunshine  WindGustSpeed  \
count  141556.0  141871.0  140787.0      81350.0   74377.0       132923.0   
mean       12.0      23.0       2.0          5.0       8.0           40.0   
std         6.0       7.0       8.0          4.0       4.0           14.0   
min        -8.0      -5.0       0.0          0.0       0.0            6.0   
25%         8.0      18.0       0.0          3.0       5.0           31.0   
50%        12.0      23.0       0.0          5.0       8.0           39.0   
75%        17.0      28.0       1.0          7.0      11.0           48.0   
max        34.0      48.0     371.0        145.0      14.0          135.0   

       WindSpeed9am  WindSpeed3pm  Humidity9am  Humidity3pm  Pressure9am  \
count      140845.0      139563.0     140419.0     138583.0     128179.0   
mean           14.0          19.0         69.0         51.0       1018.0   
std             9.0           9.0         19.0         21.0          7.0   
min             0.0           0.0          0.0          0.0        980.0   
25%             7.0          13.0         57.0         37.0       1013.0   
50%            13.0          19.0         70.0         52.0       1018.0   
75%            19.0          24.0         83.0         66.0       1022.0   
max           130.0          87.0        100.0        100.0       1041.0   

       Pressure3pm  Cloud9am  Cloud3pm   Temp9am   Temp3pm      Year  \
count     128212.0   88536.0   85099.0  141289.0  139467.0  142193.0   
mean        1015.0       4.0       5.0      17.0      22.0    2013.0   
std            7.0       3.0       3.0       6.0       7.0       3.0   
min          977.0       0.0       0.0      -7.0      -5.0    2007.0   
25%         1010.0       1.0       2.0      12.0      17.0    2011.0   
50%         1015.0       5.0       5.0      17.0      21.0    2013.0   
75%         1020.0       7.0       7.0      22.0      26.0    2015.0   
max         1040.0       9.0       9.0      40.0      47.0    2017.0   

          Month       Day  
count  142193.0  142193.0  
mean        6.0      16.0  
std         3.0       9.0  
min         1.0       1.0  
25%         3.0       8.0  
50%         6.0      16.0  
75%         9.0      23.0  
max        12.0      31.0   2
```

Rainfall, Evaporation, WindSpeed9anm WindSpeed3pm에서 최대치, 최저치차이나 평균치를 살펴보면 이상치가 포함될수 있음을 확인한다


이제는 그래프로 표현해본다

```python
plt.figure(figsize=(15,10))


plt.subplot(2, 2, 1)
fig = df.boxplot(column='Rainfall')
fig.set_title('')
fig.set_ylabel('Rainfall')


plt.subplot(2, 2, 2)
fig = df.boxplot(column='Evaporation')
fig.set_title('')
fig.set_ylabel('Evaporation')


plt.subplot(2, 2, 3)
fig = df.boxplot(column='WindSpeed9am')
fig.set_title('')
fig.set_ylabel('WindSpeed9am')


plt.subplot(2, 2, 4)
fig = df.boxplot(column='WindSpeed3pm')
fig.set_title('')
fig.set_ylabel('WindSpeed3pm')
```
```
Text(0, 0.5, 'WindSpeed3pm')
```
<img src = "https://raw.githubusercontent.com/theRepetition/therepetition.github.io/master/img/output_100_1.png">

해당 변수에 이상치가 많음을 도표로 확인할 수 있다.

### 변수 분포 확인

이번에는 히스토그램을 통해 분포를 확인한다.

이를 통해 분포가 정상적인지 확인하고 정규분포인 경우 극값분석을 수행하며 반대로 왜곡된 경우에는 사분위수 범위를 찾는다


```python
plt.figure(figsize=(15,10))


plt.subplot(2, 2, 1)
fig = df.Rainfall.hist(bins=10)
fig.set_xlabel('Rainfall')
fig.set_ylabel('RainTomorrow')


plt.subplot(2, 2, 2)
fig = df.Evaporation.hist(bins=10)
fig.set_xlabel('Evaporation')
fig.set_ylabel('RainTomorrow')


plt.subplot(2, 2, 3)
fig = df.WindSpeed9am.hist(bins=10)
fig.set_xlabel('WindSpeed9am')
fig.set_ylabel('RainTomorrow')


plt.subplot(2, 2, 4)
fig = df.WindSpeed3pm.hist(bins=10)
fig.set_xlabel('WindSpeed3pm')
fig.set_ylabel('RainTomorrow')
```
```
Text(0, 0.5, 'RainTomorrow')
```

<img src = "https://raw.githubusercontent.com/theRepetition/therepetition.github.io/master/img/output_103_1.png">

네가지 변수가 모두 왜곡되어있으므로, 사분위구간의 범위를 사용해 이상치를 찾아준다

```python
IQR = df.Rainfall.quantile(0.75) - df.Rainfall.quantile(0.25)
Lower_fence = df.Rainfall.quantile(0.25) - (IQR * 3)
Upper_fence = df.Rainfall.quantile(0.75) + (IQR * 3)
print('Rainfall outliers are values < {lowerboundary} or > {upperboundary}'.format(lowerboundary=Lower_fence, upperboundary=Upper_fence))
```
>Rainfall outliers are values < -2.4000000000000004 or > 3.2

Rainfall의 경우 최소치와 최대치 차이가 3.2를 초과하는 경우 이상치로 취급한다.

```python
IQR = df.Evaporation.quantile(0.75) - df.Evaporation.quantile(0.25)
Lower_fence = df.Evaporation.quantile(0.25) - (IQR * 3)
Upper_fence = df.Evaporation.quantile(0.75) + (IQR * 3)
print('Evaporation outliers are values < {lowerboundary} or > {upperboundary}'.format(lowerbou
```
>Evaporation outliers are values < -11.800000000000002 or > 21.800000000000004
Evaporation의 경우에는 21.8을 넘는 경우이다

```python
IQR = df.WindSpeed9am.quantile(0.75) - df.WindSpeed9am.quantile(0.25)
Lower_fence = df.WindSpeed9am.quantile(0.25) - (IQR * 3)
Upper_fence = df.WindSpeed9am.quantile(0.75) + (IQR * 3)
print('WindSpeed9am outliers are values < {lowerboundary} or > {upperboundary}'.format(lowerboundary=Lower_fence, upperboundary=Upper_fence))
```
>WindSpeed9am outliers are values < -29.0 or > 55.0

WindSpeed9am의 경우 55를 초과하는 경우이다.

```python
IQR = df.WindSpeed3pm.quantile(0.75) - df.WindSpeed3pm.quantile(0.25)
Lower_fence = df.WindSpeed3pm.quantile(0.25) - (IQR * 3)
Upper_fence = df.WindSpeed3pm.quantile(0.75) + (IQR * 3)
print('WindSpeed3pm outliers are values < {lowerboundary} or > {upperboundary}'.format(lowerboundary=Lower_fence, upperboundary=Upper_fence))
```
>WindSpeed3pm outliers are values < -20.0 or > 57.0

WindSpeed3Pm은 57을 넘으면 이상치로 취급한다




---
## 8.특징 벡터 대상 변수 선언

```python
X = df.drop(['RainTomorrow'], axis=1)
y = df['RainTomorrow']
```
---
## 9.데이터를 학습과 테스트 셋으로 분할

x와 y로 분리해서 학습과 테스트 셋으로 분할한다
```python
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)
```

shape로 확인
```python
X_train.shape, X_test.shape
```
>((113754, 24), (28439, 24))


---
## 10.특성 처리

특성 처리는 원시 데이터를 유용한 특성으로 변환한다.

여러 유형의 변수에 대해 특성 처리를 실행한다.

먼저 범주형, 수치형 변수를 구분해본다.

```python
X_train.dtypes
```
```
Location          object
MinTemp          float64
MaxTemp          float64
Rainfall         float64
Evaporation      float64
Sunshine         float64
WindGustDir       object
WindGustSpeed    float64
WindDir9am        object
WindDir3pm        object
WindSpeed9am     float64
WindSpeed3pm     float64
Humidity9am      float64
Humidity3pm      float64
Pressure9am      float64
Pressure3pm      float64
Cloud9am         float64
Cloud3pm         float64
Temp9am          float64
Temp3pm          float64
RainToday         object
Year               int64
Month              int64
Day                int64
dtype: object
```

범주형 변수만 표시

```python
categorical = [col for col in X_train.columns if X_train[col].dtypes == 'O']

categorical
```

```
['Location', 'WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday']
```

수치형 변수 표시
```python
numerical = [col for col in X_train.columns if X_train[col].dtypes != 'O']

numerical
```

```
['MinTemp',
 'MaxTemp',
 'Rainfall',
 'Evaporation',
 'Sunshine',
 'WindGustSpeed',
 'WindSpeed9am',
 'WindSpeed3pm',
 'Humidity9am',
 'Humidity3pm',
 'Pressure9am',
 'Pressure3pm',
 'Cloud9am',
 'Cloud3pm',
 'Temp9am',
 'Temp3pm',
 'Year',
 'Month',
 'Day']
```

### 수치형 변수에서 결측치 해결

먼저 X_Trian에서 결측치를 찾아준다

```python
X_train[numerical].isnull().sum()
```
```
MinTemp            495
MaxTemp            264
Rainfall          1139
Evaporation      48718
Sunshine         54314
WindGustSpeed     7367
WindSpeed9am      1086
WindSpeed3pm      2094
Humidity9am       1449
Humidity3pm       2890
Pressure9am      11212
Pressure3pm      11186
Cloud9am         43137
Cloud3pm         45768
Temp9am            740
Temp3pm           2171
Year                 0
Month                0
Day                  0
```
이번에는 X_test에서 찾아준다

```python
X_test[numerical].isnull().sum()
```
```
MinTemp            142
MaxTemp             58
Rainfall           267
Evaporation      12125
Sunshine         13502
WindGustSpeed     1903
WindSpeed9am       262
WindSpeed3pm       536
Humidity9am        325
Humidity3pm        720
Pressure9am       2802
Pressure3pm       2795
Cloud9am         10520
Cloud3pm         11326
Temp9am            164
Temp3pm            555
Year                 0
Month                0
Day                  0
dtype: int64
```

### 가정

데이터중 결측치가 어떤 연속성을 갖는것이 아니라 완전히 무작위적으로 누락되었다고 가정하자.

이때 두가지 방법으로 결측치를 해결할 수 있다.

1. 평균-중앙값
2. 무작위 샘플

데이터 셋에 이상치가 있는 경우에는 중앙값 보정이 유리하기 때문에 중앙값 보정을 사용 해본다.

데이터의 적절한 통계적 측정값을 사용해 결측치를 추정하는데, 추정은 훈련셋에 먼저 수행하고 테스트 셋을 진행한다.

훈련셋에서 추출한 중앙값을 바탕으로 훈련셋, 테스트셋 모두 결측치를 채워 과적합을 피해준다.


훈련셋을 기반으로 결측치를 체워준다.
```python
for df1 in [X_train, X_test]:
    for col in numerical:
        col_median=X_train[col].median()
        df1[col].fillna(col_median, inplace=True) 
```
훈련셋 결측치 해결 확인

```python
X_train[numerical].isnull().sum()
```
```
MinTemp          0
MaxTemp          0
Rainfall         0
Evaporation      0
Sunshine         0
WindGustSpeed    0
WindSpeed9am     0
WindSpeed3pm     0
Humidity9am      0
Humidity3pm      0
Pressure9am      0
Pressure3pm      0
Cloud9am         0
Cloud3pm         0
Temp9am          0
Temp3pm          0
Year             0
Month            0
Day              0
dtype: int64

```
테스트 셋 결측치 해결 확인

```python
X_test[numerical].isnull().sum()
```
```
MinTemp          0
MaxTemp          0
Rainfall         0
Evaporation      0
Sunshine         0
WindGustSpeed    0
WindSpeed9am     0
WindSpeed3pm     0
Humidity9am      0
Humidity3pm      0
Pressure9am      0
Pressure3pm      0
Cloud9am         0
Cloud3pm         0
Temp9am          0
Temp3pm          0
Year             0
Month            0
Day              0
dtype: int64
```

이제 훈련셋, 테스트 셋 모두 결측치가 없음을 확인할 수 있다.

### 범주형 변수의 결측치 해결

범주형 변수의 결측치 비율은 다음과 같다.

```python
X_train[categorical].isnull().mean()
```
```
Location       0.000000
WindGustDir    0.065114
WindDir9am     0.070134
WindDir3pm     0.026443
RainToday      0.010013
dtype: float64
```
마찬가지로 범주형 변수에서 결측치는 훈련셋을 기반으로 하되, 최빈값으로 대입한다.
```python

for df2 in [X_train, X_test]:
    df2['WindGustDir'].fillna(X_train['WindGustDir'].mode()[0], inplace=True)
    df2['WindDir9am'].fillna(X_train['WindDir9am'].mode()[0], inplace=True)
    df2['WindDir3pm'].fillna(X_train['WindDir3pm'].mode()[0], inplace=True)
    df2['RainToday'].fillna(X_train['RainToday'].mode()[0], inplace=True)
```

훈련 셋 결측치 확인
```python
X_train[categorical].isnull().sum()
```
```
Location       0
WindGustDir    0
WindDir9am     0
WindDir3pm     0
RainToday      0
dtype: int64
```
테스트 셋 결측치 확인
```python
X_test[categorical].isnull().sum()
```
```
Location       0
WindGustDir    0
WindDir9am     0
WindDir3pm     0
RainToday      0
dtype: int64
```
마지막으로 양쪽 셋 전체의 결측치를 확인해준다
```python
X_train.isnull().sum()
```
```
Location         0
MinTemp          0
MaxTemp          0
Rainfall         0
Evaporation      0
Sunshine         0
WindGustDir      0
WindGustSpeed    0
WindDir9am       0
WindDir3pm       0
WindSpeed9am     0
WindSpeed3pm     0
Humidity9am      0
Humidity3pm      0
Pressure9am      0
Pressure3pm      0
Cloud9am         0
Cloud3pm         0
Temp9am          0
Temp3pm          0
RainToday        0
Year             0
Month            0
Day              0
dtype: int64
```
```python
X_test.isnull().sum()
```
```
Location         0
MinTemp          0
MaxTemp          0
Rainfall         0
Evaporation      0
Sunshine         0
WindGustDir      0
WindGustSpeed    0
WindDir9am       0
WindDir3pm       0
WindSpeed9am     0
WindSpeed3pm     0
Humidity9am      0
Humidity3pm      0
Pressure9am      0
Pressure3pm      0
Cloud9am         0
Cloud3pm         0
Temp9am          0
Temp3pm          0
RainToday        0
Year             0
Month            0
Day              0
dtype: int64
```


### 수치형 변수의 이상치 해결

이전에 Rainfall, Evaporation, WindSpeed9am, WindSpeed3pm에 이상치가 있음을 확인했다.

따라서 이 이상치를 제거하기 위해 탑 코딩 방식을 사용한다.

```python
def max_value(df3, variable, top):
    return np.where(df3[variable]>top, top, df3[variable])

for df3 in [X_train, X_test]:
    df3['Rainfall'] = max_value(df3, 'Rainfall', 3.2)
    df3['Evaporation'] = max_value(df3, 'Evaporation', 21.8)
    df3['WindSpeed9am'] = max_value(df3, 'WindSpeed9am', 55)
    df3['WindSpeed3pm'] = max_value(df3, 'WindSpeed3pm', 57)
```
```python
X_train.Rainfall.max(), X_test.Rainfall.max()
```
>(3.2, 3.2)
```python
X_train.Evaporation.max(), X_test.Evaporation.max()
```
>(21.8 21.8)
```python
X_train.WindSpeed9am.max(), X_test.WindSpeed9am.max()
```
> (55.0, 55.0)
```python
X_train.WindSpeed3pm.max(), X_test.WindSpeed3pm.max()
```
>(57.0, 57.0)
```python
X_train[numerical].describe()
```
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>MinTemp</th>
      <th>MaxTemp</th>
      <th>Rainfall</th>
      <th>Evaporation</th>
      <th>Sunshine</th>
      <th>WindGustSpeed</th>
      <th>WindSpeed9am</th>
      <th>WindSpeed3pm</th>
      <th>Humidity9am</th>
      <th>Humidity3pm</th>
      <th>Pressure9am</th>
      <th>Pressure3pm</th>
      <th>Cloud9am</th>
      <th>Cloud3pm</th>
      <th>Temp9am</th>
      <th>Temp3pm</th>
      <th>Year</th>
      <th>Month</th>
      <th>Day</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>113754.000000</td>
      <td>113754.000000</td>
      <td>113754.000000</td>
      <td>113754.000000</td>
      <td>113754.000000</td>
      <td>113754.000000</td>
      <td>113754.000000</td>
      <td>113754.000000</td>
      <td>113754.000000</td>
      <td>113754.000000</td>
      <td>113754.000000</td>
      <td>113754.000000</td>
      <td>113754.000000</td>
      <td>113754.000000</td>
      <td>113754.000000</td>
      <td>113754.000000</td>
      <td>113754.000000</td>
      <td>113754.000000</td>
      <td>113754.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>12.193497</td>
      <td>23.237216</td>
      <td>0.675080</td>
      <td>5.151606</td>
      <td>8.041154</td>
      <td>39.884074</td>
      <td>13.978155</td>
      <td>18.614756</td>
      <td>68.867486</td>
      <td>51.509547</td>
      <td>1017.640649</td>
      <td>1015.241101</td>
      <td>4.651801</td>
      <td>4.703588</td>
      <td>16.995062</td>
      <td>21.688643</td>
      <td>2012.759727</td>
      <td>6.404021</td>
      <td>15.710419</td>
    </tr>
    <tr>
      <th>std</th>
      <td>6.388279</td>
      <td>7.094149</td>
      <td>1.183837</td>
      <td>2.823707</td>
      <td>2.769480</td>
      <td>13.116959</td>
      <td>8.806558</td>
      <td>8.685862</td>
      <td>18.935587</td>
      <td>20.530723</td>
      <td>6.738680</td>
      <td>6.675168</td>
      <td>2.292726</td>
      <td>2.117847</td>
      <td>6.463772</td>
      <td>6.855649</td>
      <td>2.540419</td>
      <td>3.427798</td>
      <td>8.796821</td>
    </tr>
    <tr>
      <th>min</th>
      <td>-8.200000</td>
      <td>-4.800000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>6.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>980.500000</td>
      <td>977.100000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>-7.200000</td>
      <td>-5.400000</td>
      <td>2007.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>7.600000</td>
      <td>18.000000</td>
      <td>0.000000</td>
      <td>4.000000</td>
      <td>8.200000</td>
      <td>31.000000</td>
      <td>7.000000</td>
      <td>13.000000</td>
      <td>57.000000</td>
      <td>37.000000</td>
      <td>1013.500000</td>
      <td>1011.000000</td>
      <td>3.000000</td>
      <td>4.000000</td>
      <td>12.300000</td>
      <td>16.700000</td>
      <td>2011.000000</td>
      <td>3.000000</td>
      <td>8.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>12.000000</td>
      <td>22.600000</td>
      <td>0.000000</td>
      <td>4.800000</td>
      <td>8.500000</td>
      <td>39.000000</td>
      <td>13.000000</td>
      <td>19.000000</td>
      <td>70.000000</td>
      <td>52.000000</td>
      <td>1017.600000</td>
      <td>1015.200000</td>
      <td>5.000000</td>
      <td>5.000000</td>
      <td>16.700000</td>
      <td>21.100000</td>
      <td>2013.000000</td>
      <td>6.000000</td>
      <td>16.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>16.800000</td>
      <td>28.200000</td>
      <td>0.600000</td>
      <td>5.400000</td>
      <td>8.700000</td>
      <td>46.000000</td>
      <td>19.000000</td>
      <td>24.000000</td>
      <td>83.000000</td>
      <td>65.000000</td>
      <td>1021.800000</td>
      <td>1019.400000</td>
      <td>6.000000</td>
      <td>6.000000</td>
      <td>21.500000</td>
      <td>26.300000</td>
      <td>2015.000000</td>
      <td>9.000000</td>
      <td>23.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>33.900000</td>
      <td>48.100000</td>
      <td>3.200000</td>
      <td>21.800000</td>
      <td>14.500000</td>
      <td>135.000000</td>
      <td>55.000000</td>
      <td>57.000000</td>
      <td>100.000000</td>
      <td>100.000000</td>
      <td>1041.000000</td>
      <td>1039.600000</td>
      <td>9.000000</td>
      <td>8.000000</td>
      <td>40.200000</td>
      <td>46.700000</td>
      <td>2017.000000</td>
      <td>12.000000</td>
      <td>31.000000</td>
    </tr>
  </tbody>
</table>
</div>


이제 Rainfall, Evaporation, WindSpeed9am, WIndSpeed3pm 열의 이상치가 상한선을 넘은것을 확인할 수 있다.

### 범주형 변수의 이상치 해결
```python
categorical
```
> ['Location', 'WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday']

```python
X_train[categorical].head()
```
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Location</th>
      <th>WindGustDir</th>
      <th>WindDir9am</th>
      <th>WindDir3pm</th>
      <th>RainToday</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>110803</th>
      <td>Witchcliffe</td>
      <td>S</td>
      <td>SSE</td>
      <td>S</td>
      <td>No</td>
    </tr>
    <tr>
      <th>87289</th>
      <td>Cairns</td>
      <td>ENE</td>
      <td>SSE</td>
      <td>SE</td>
      <td>Yes</td>
    </tr>
    <tr>
      <th>134949</th>
      <td>AliceSprings</td>
      <td>E</td>
      <td>NE</td>
      <td>N</td>
      <td>No</td>
    </tr>
    <tr>
      <th>85553</th>
      <td>Cairns</td>
      <td>ESE</td>
      <td>SSE</td>
      <td>E</td>
      <td>No</td>
    </tr>
    <tr>
      <th>16110</th>
      <td>Newcastle</td>
      <td>W</td>
      <td>N</td>
      <td>SE</td>
      <td>No</td>
    </tr>
  </tbody>
</table>

RainToday 처리

```python

import category_encoders as ce

encoder = ce.BinaryEncoder(cols=['RainToday'])

X_train = encoder.fit_transform(X_train)

X_test = encoder.transform(X_test)

```

<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Location</th>
      <th>MinTemp</th>
      <th>MaxTemp</th>
      <th>Rainfall</th>
      <th>Evaporation</th>
      <th>Sunshine</th>
      <th>WindGustDir</th>
      <th>WindGustSpeed</th>
      <th>WindDir9am</th>
      <th>WindDir3pm</th>
      <th>...</th>
      <th>Pressure3pm</th>
      <th>Cloud9am</th>
      <th>Cloud3pm</th>
      <th>Temp9am</th>
      <th>Temp3pm</th>
      <th>RainToday_0</th>
      <th>RainToday_1</th>
      <th>Year</th>
      <th>Month</th>
      <th>Day</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>110803</th>
      <td>Witchcliffe</td>
      <td>13.9</td>
      <td>22.6</td>
      <td>0.2</td>
      <td>4.8</td>
      <td>8.5</td>
      <td>S</td>
      <td>41.0</td>
      <td>SSE</td>
      <td>S</td>
      <td>...</td>
      <td>1013.4</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>18.8</td>
      <td>20.4</td>
      <td>0</td>
      <td>1</td>
      <td>2014</td>
      <td>4</td>
      <td>25</td>
    </tr>
    <tr>
      <th>87289</th>
      <td>Cairns</td>
      <td>22.4</td>
      <td>29.4</td>
      <td>2.0</td>
      <td>6.0</td>
      <td>6.3</td>
      <td>ENE</td>
      <td>33.0</td>
      <td>SSE</td>
      <td>SE</td>
      <td>...</td>
      <td>1013.1</td>
      <td>7.0</td>
      <td>5.0</td>
      <td>26.4</td>
      <td>27.5</td>
      <td>1</td>
      <td>0</td>
      <td>2015</td>
      <td>11</td>
      <td>2</td>
    </tr>
    <tr>
      <th>134949</th>
      <td>AliceSprings</td>
      <td>9.7</td>
      <td>36.2</td>
      <td>0.0</td>
      <td>11.4</td>
      <td>12.3</td>
      <td>E</td>
      <td>31.0</td>
      <td>NE</td>
      <td>N</td>
      <td>...</td>
      <td>1013.6</td>
      <td>1.0</td>
      <td>1.0</td>
      <td>28.5</td>
      <td>35.0</td>
      <td>0</td>
      <td>1</td>
      <td>2014</td>
      <td>10</td>
      <td>19</td>
    </tr>
    <tr>
      <th>85553</th>
      <td>Cairns</td>
      <td>20.5</td>
      <td>30.1</td>
      <td>0.0</td>
      <td>8.8</td>
      <td>11.1</td>
      <td>ESE</td>
      <td>37.0</td>
      <td>SSE</td>
      <td>E</td>
      <td>...</td>
      <td>1010.8</td>
      <td>2.0</td>
      <td>3.0</td>
      <td>27.3</td>
      <td>29.4</td>
      <td>0</td>
      <td>1</td>
      <td>2010</td>
      <td>10</td>
      <td>30</td>
    </tr>
    <tr>
      <th>16110</th>
      <td>Newcastle</td>
      <td>16.8</td>
      <td>29.2</td>
      <td>0.0</td>
      <td>4.8</td>
      <td>8.5</td>
      <td>W</td>
      <td>39.0</td>
      <td>N</td>
      <td>SE</td>
      <td>...</td>
      <td>1015.2</td>
      <td>5.0</td>
      <td>8.0</td>
      <td>22.2</td>
      <td>27.0</td>
      <td>0</td>
      <td>1</td>
      <td>2012</td>
      <td>11</td>
      <td>8</td>
    </tr>
  </tbody>
</table>
<p>5 rows x 25 columns</p>

여기서 RainToday_1과 RainToday_2가 생성되었다.

이제 훈련셋에서도 만들어준다.


```python
X_train = pd.concat([X_train[numerical], X_train[['RainToday_0', 'RainToday_1']],
                     pd.get_dummies(X_train.Location), 
                     pd.get_dummies(X_train.WindGustDir),
                     pd.get_dummies(X_train.WindDir9am),
                     pd.get_dummies(X_train.WindDir3pm)], axis=1)
```
```python
X_train.head()
```
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>MinTemp</th>
      <th>MaxTemp</th>
      <th>Rainfall</th>
      <th>Evaporation</th>
      <th>Sunshine</th>
      <th>WindGustSpeed</th>
      <th>WindSpeed9am</th>
      <th>WindSpeed3pm</th>
      <th>Humidity9am</th>
      <th>Humidity3pm</th>
      <th>...</th>
      <th>NNW</th>
      <th>NW</th>
      <th>S</th>
      <th>SE</th>
      <th>SSE</th>
      <th>SSW</th>
      <th>SW</th>
      <th>W</th>
      <th>WNW</th>
      <th>WSW</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>110803</th>
      <td>13.9</td>
      <td>22.6</td>
      <td>0.2</td>
      <td>4.8</td>
      <td>8.5</td>
      <td>41.0</td>
      <td>20.0</td>
      <td>28.0</td>
      <td>65.0</td>
      <td>55.0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>87289</th>
      <td>22.4</td>
      <td>29.4</td>
      <td>2.0</td>
      <td>6.0</td>
      <td>6.3</td>
      <td>33.0</td>
      <td>7.0</td>
      <td>19.0</td>
      <td>71.0</td>
      <td>59.0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>134949</th>
      <td>9.7</td>
      <td>36.2</td>
      <td>0.0</td>
      <td>11.4</td>
      <td>12.3</td>
      <td>31.0</td>
      <td>15.0</td>
      <td>11.0</td>
      <td>6.0</td>
      <td>2.0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>85553</th>
      <td>20.5</td>
      <td>30.1</td>
      <td>0.0</td>
      <td>8.8</td>
      <td>11.1</td>
      <td>37.0</td>
      <td>22.0</td>
      <td>19.0</td>
      <td>59.0</td>
      <td>53.0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>16110</th>
      <td>16.8</td>
      <td>29.2</td>
      <td>0.0</td>
      <td>4.8</td>
      <td>8.5</td>
      <td>39.0</td>
      <td>0.0</td>
      <td>7.0</td>
      <td>72.0</td>
      <td>53.0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>

비슷하게 테스트 셋으로도 만들어준다.

```python
X_test = pd.concat([X_test[numerical], X_test[['RainToday_0', 'RainToday_1']],
                     pd.get_dummies(X_test.Location), 
                     pd.get_dummies(X_test.WindGustDir),
                     pd.get_dummies(X_test.WindDir9am),
                     pd.get_dummies(X_test.WindDir3pm)], axis=1)
```

```python
X_test.head()
```
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>MinTemp</th>
      <th>MaxTemp</th>
      <th>Rainfall</th>
      <th>Evaporation</th>
      <th>Sunshine</th>
      <th>WindGustSpeed</th>
      <th>WindSpeed9am</th>
      <th>WindSpeed3pm</th>
      <th>Humidity9am</th>
      <th>Humidity3pm</th>
      <th>...</th>
      <th>NNW</th>
      <th>NW</th>
      <th>S</th>
      <th>SE</th>
      <th>SSE</th>
      <th>SSW</th>
      <th>SW</th>
      <th>W</th>
      <th>WNW</th>
      <th>WSW</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>86232</th>
      <td>17.4</td>
      <td>29.0</td>
      <td>0.0</td>
      <td>3.6</td>
      <td>11.1</td>
      <td>33.0</td>
      <td>11.0</td>
      <td>19.0</td>
      <td>63.0</td>
      <td>61.0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>57576</th>
      <td>6.8</td>
      <td>14.4</td>
      <td>0.8</td>
      <td>0.8</td>
      <td>8.5</td>
      <td>46.0</td>
      <td>17.0</td>
      <td>22.0</td>
      <td>80.0</td>
      <td>55.0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>124071</th>
      <td>10.1</td>
      <td>15.4</td>
      <td>3.2</td>
      <td>4.8</td>
      <td>8.5</td>
      <td>31.0</td>
      <td>13.0</td>
      <td>9.0</td>
      <td>70.0</td>
      <td>61.0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>117955</th>
      <td>14.4</td>
      <td>33.4</td>
      <td>0.0</td>
      <td>8.0</td>
      <td>11.6</td>
      <td>41.0</td>
      <td>9.0</td>
      <td>17.0</td>
      <td>40.0</td>
      <td>23.0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>133468</th>
      <td>6.8</td>
      <td>14.3</td>
      <td>3.2</td>
      <td>0.2</td>
      <td>7.3</td>
      <td>28.0</td>
      <td>15.0</td>
      <td>13.0</td>
      <td>92.0</td>
      <td>47.0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>

이제 모델 구축을 위한 훈련/테스트가 준비되었다.

이제 특징변수를 모두 동일한 척도로 적용시키는 특성 스케일링을 진행해야 한다.

---
## 11.특성 스케일링

```python
cols = X_train.columns


from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
X_train = pd.DataFrame(X_train, columns=[cols])
X_test = pd.DataFrame(X_test, columns=[cols])



X_train.describe()

```
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th>MinTemp</th>
      <th>MaxTemp</th>
      <th>Rainfall</th>
      <th>Evaporation</th>
      <th>Sunshine</th>
      <th>WindGustSpeed</th>
      <th>WindSpeed9am</th>
      <th>WindSpeed3pm</th>
      <th>Humidity9am</th>
      <th>Humidity3pm</th>
      <th>...</th>
      <th>NNW</th>
      <th>NW</th>
      <th>S</th>
      <th>SE</th>
      <th>SSE</th>
      <th>SSW</th>
      <th>SW</th>
      <th>W</th>
      <th>WNW</th>
      <th>WSW</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>113754.000000</td>
      <td>113754.000000</td>
      <td>113754.000000</td>
      <td>113754.000000</td>
      <td>113754.000000</td>
      <td>113754.000000</td>
      <td>113754.000000</td>
      <td>113754.000000</td>
      <td>113754.000000</td>
      <td>113754.000000</td>
      <td>...</td>
      <td>113754.000000</td>
      <td>113754.000000</td>
      <td>113754.000000</td>
      <td>113754.000000</td>
      <td>113754.000000</td>
      <td>113754.000000</td>
      <td>113754.000000</td>
      <td>113754.000000</td>
      <td>113754.000000</td>
      <td>113754.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>0.484406</td>
      <td>0.530004</td>
      <td>0.210962</td>
      <td>0.236312</td>
      <td>0.554562</td>
      <td>0.262667</td>
      <td>0.254148</td>
      <td>0.326575</td>
      <td>0.688675</td>
      <td>0.515095</td>
      <td>...</td>
      <td>0.054530</td>
      <td>0.060288</td>
      <td>0.067259</td>
      <td>0.101605</td>
      <td>0.064059</td>
      <td>0.056402</td>
      <td>0.064464</td>
      <td>0.069334</td>
      <td>0.060798</td>
      <td>0.065483</td>
    </tr>
    <tr>
      <th>std</th>
      <td>0.151741</td>
      <td>0.134105</td>
      <td>0.369949</td>
      <td>0.129528</td>
      <td>0.190999</td>
      <td>0.101682</td>
      <td>0.160119</td>
      <td>0.152384</td>
      <td>0.189356</td>
      <td>0.205307</td>
      <td>...</td>
      <td>0.227061</td>
      <td>0.238021</td>
      <td>0.250471</td>
      <td>0.302130</td>
      <td>0.244860</td>
      <td>0.230698</td>
      <td>0.245578</td>
      <td>0.254022</td>
      <td>0.238960</td>
      <td>0.247378</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>0.375297</td>
      <td>0.431002</td>
      <td>0.000000</td>
      <td>0.183486</td>
      <td>0.565517</td>
      <td>0.193798</td>
      <td>0.127273</td>
      <td>0.228070</td>
      <td>0.570000</td>
      <td>0.370000</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>0.479810</td>
      <td>0.517958</td>
      <td>0.000000</td>
      <td>0.220183</td>
      <td>0.586207</td>
      <td>0.255814</td>
      <td>0.236364</td>
      <td>0.333333</td>
      <td>0.700000</td>
      <td>0.520000</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>0.593824</td>
      <td>0.623819</td>
      <td>0.187500</td>
      <td>0.247706</td>
      <td>0.600000</td>
      <td>0.310078</td>
      <td>0.345455</td>
      <td>0.421053</td>
      <td>0.830000</td>
      <td>0.650000</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>...</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>


---
## 12.모델 학습

이번에는 훈련 집합에 대한 로지스틱 회귀 모델 훈련을 실행한다.

```python
from sklearn.linear_model import LogisticRegression
logreg = LogisticRegression(solver='liblinear', random_state=0)
logreg.fit(X_train, y_train)
```
```
LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='warn', n_jobs=None, penalty='l2',
                   random_state=0, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
```
---
## 13.결과 예측

```python
y_pred_test = logreg.predict(X_test)
y_pred_test
```
> array(['No', 'No', 'No', ..., 'No', 'No', 'Yes'], dtype=object)

### 예측프로바 메서드
예측 프로바 메서드는 대상 변수에 대한 확률을 배열 형식으로 제공한다.
```python
logreg.predict_proba(X_test)[:,0]
```
> array([0.91382428, 0.83565645, 0.82033915, ..., 0.97674285, 0.79855098,
       0.30734161])

```python
logreg.predict_proba(X_test)[:,1]
```
> array([0.08617572, 0.16434355, 0.17966085, ..., 0.02325715, 0.20144902,
       0.69265839])





---
## 14.정확한 점수 예측


여기서 y_test는 실제, Y_pred_test는 테스트 집합에서 예측된 클래스 레이블이다.
```python
from sklearn.metrics import accuracy_score
print('Model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_pred_test)))
```
> Model accuracy score: 0.8502

### 이제 학습 셋과 테스트 셋의 정확도를 비교한다.

```python
y_pred_train = logreg.predict(X_train)
y_pred_train
```
>array(['No', 'No', 'No', ..., 'No', 'No', 'No'], dtype=object)


```python
print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))
```
>Training-set accuracy score: 0.8476

오버핏, 언더핏 확인

```python
print('Training set score: {:.4f}'.format(logreg.score(X_train, y_train)))
print('Test set score: {:.4f}'.format(logreg.score(X_test, y_test)))
```
> Training set score: 0.8476
> Test set score: 0.8502
훈련 셋의 정확도는 0.85에 조금 못미치고 테스트 셋은 0.85로 상당히 비슷해, 오버핏은 아니다.

로지스틱 회귀에서는 기본값인 C=1을 사용하기 떄문에 두 셋 모두 85%로 성능이 높은 편이다.

그러나 훈련과, 테스트 모두 모델성능이 비슷하기 때문에, 과소 적합일 가능성이 있다.

C를 올려 더 유연한 모델로 시도해본다.

```python
logreg100 = LogisticRegression(C=100, solver='liblinear', random_state=0)
logreg100.fit(X_train, y_train)
```
```
LogisticRegression(C=100, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='warn', n_jobs=None, penalty='l2',
                   random_state=0, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
```

'''python
print('Training set score: {:.4f}'.format(logreg100.score(X_train, y_train)))
print('Test set score: {:.4f}'.format(logreg100.score(X_test, y_test)))
'''
> Training set score: 0.8478
> Test set score: 0.8505

C=100이 양쪽 세트의 정확도를 약간 증가시킨것을 확인 할수 있다.

따라서 모델이 복잡할수록 더 나은 성능을 발휘할것이다.

이번에는 C를 0.01로 설정해 더 정규화된 모델일 경우 어떤 결과가 나오는지 확인해본다.

```python
logreg001 = LogisticRegression(C=0.01, solver='liblinear', random_state=0)
logreg001.fit(X_train, y_train)
```
```
LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='warn', n_jobs=None, penalty='l2',
                   random_state=0, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
```

```python

print('Training set score: {:.4f}'.format(logreg001.score(X_train, y_train)))

print('Test set score: {:.4f}'.format(logreg001.score(X_test, y_test)))
```
> Training set score: 0.8409
> Test set score: 0.8448

확실히 정규화된 모델의 경우 성능이 낮아진 것을 확인할수 있다.

### 모델 정확도와 널 정확도 비교

모델 정확도가 0.8501인데, 위의 정확도 외에 널 정확도와 비교해 더 확실하게 한다.

널 정확도는 항상 빈번한 클래스를 예측해 얻을 수 있다.

먼저 테스트 셋의 클래스 분포를 확인해준다.

```python
y_test.value_counts()
```
```
No     22067
Yes     6372
Name: RainTomorrow, dtype: int64
```
가장 빈번한 클래스의 경우 22067인것을 알 수 있다.

따라서 22067을 총 발생 횟수로 나누면 널 정확도를 계산 할 수 있다.

```python
null_accuracy = (22067/(22067+6372))

print('Null accuracy score: {0:0.4f}'. format(null_accuracy))
```
> Null accuracy score: 0.7759

널 정확도의 경우 0.77로 기존의 0.85정도 보다는 나지만 로지스틱 회귀 모델이 잘 작동하고 있음을 확인 할 수있다.

그러나 기본값의 분포는 제공하지 않는다.

또한 분류기가 어떤 유형의 오류를 범하고 있는지도 알 수 없다.

따라서 혼돈 행렬을 사용해준다.


---
## 15.혼돈 행렬

혼돈 행렬은 분류 알고리즘의 성능을 요약하는 도구이다. 

혼돈 행렬은 분류 모델의 성능과 모델에서 발생하는 오류 유형을 파악하게 해주는데

각 범주별로 분류된 올바른 예측과 예약을 표 형식으로 제공한다

분류 모델 성능은 4가지 결과로 나온다

1. TP 특정 클래스에 속할것을 예측한 경우, 정확하게 예측 했을경우
 
2. FP 특정 클래스에 속할것을 예측했지만 예측이 틀린 경우
 
3. TN 특정 클래스에 속하지 않는다고 예측할경우, 정확하게 예측한 경우
 
4. FN 특정 클래스에 속하지 않는다고 예츠했는데 예측이 틀린 경우

다음은 예측 결과이다.

```python
from sklearn.metrics import confusion_matrix

cm = confusion_matrix(y_test, y_pred_test)

print('Confusion matrix\n\n', cm)

print('\nTrue Positives(TP) = ', cm[0,0])

print('\nTrue Negatives(TN) = ', cm[1,1])

print('\nFalse Positives(FP) = ', cm[0,1])

print('\nFalse Negatives(FN) = ', cm[1,0])
```
```
Confusion matrix

 [[20892  1175]
 [ 3086  3286]]

True Positives(TP) =  20892

True Negatives(TN) =  3286

False Positives(FP) =  1175

False Negatives(FN) =  3086
```

* TP는 20982
* TN은 9286
* FP는 1175 (에러 1)
* FN은 3086 (에러 2)

모델을 도표로 표현할 수 도 있다.
``` python
cm_matrix = pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'], 
                                 index=['Predict Positive:1', 'Predict Negative:0'])

sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')
```

<img src="https://raw.githubusercontent.com/theRepetition/therepetition.github.io/master/img/output_202_1.png">

---
## 16.분류 지표

분류 지표는 분류 모델 성능을 평가하는 또 다른 방법이다.

여기에는 모델의 정밀도, 재현율, F1및 지원 점수가 표기된다.

다음과 같이 사용할 수 있다.

```python
from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred_test))

```
```
              precision    recall  f1-score   support

          No       0.87      0.95      0.91     22067
         Yes       0.74      0.52      0.61      6372

    accuracy                           0.85     28439
   macro avg       0.80      0.73      0.76     28439
weighted avg       0.84      0.85      0.84     28439
```

### 분류 정확도

```python
TP = cm[0,0]
TN = cm[1,1]
FP = cm[0,1]
FN = cm[1,0]
classification_accuracy = (TP + TN) / float(TP + TN + FP + FN)
print('Classification accuracy : {0:0.4f}'.format(classification_accuracy))
```
> Classification accuracy : 0.8502

### 분류 오류

```python
classification_error = (FP + FN) / float(TP + TN + FP + FN)
print('Classification error : {0:0.4f}'.format(classification_error))
```
> Classification error : 0.1498

### 정밀도

정밀도는 예측된 positive중 올바르게 예측된 positive결과의 비율로 정의할수 있다.

따라서 TP를 TP+ FP로 나눈 비율로 나타낼 수 있다.

```python
precision = TP / float(TP + FP)
print('Precision : {0:0.4f}'.format(precision))
```
> Precision : 0.9468

### 재현율

재현율은 실제 positive중 정확하게 예측된 positive의 비율로 나타낼수 있다.

따라서 TP를 TP+FN으로 나눈 비율로 나타 낼수 있다

```python
recall = TP / float(TP + FN)
print('Recall or Sensitivity : {0:0.4f}'.format(recall))
```
> Recall or Sensitivity : 0.8713

### TP 비율
```python
true_positive_rate = TP / float(TP + FN)
print('True Positive Rate : {0:0.4f}'.format(true_positive_rate))
```
> True Positive Rate : 0.8713

### FP 비율
```python
false_positive_rate = FP / float(FP + TN)
print('False Positive Rate : {0:0.4f}'.format(false_positive_rate))
```
> False Positive Rate : 0.2634

### 구체성
```python
specificity = TN / (TN + FP)
print('Specificity : {0:0.4f}'.format(specificity))
```
> Specificity : 0.7366

### f1점수
f1점수는 정확도와 재현율의 가중치 조화 평균이다.

따라서 최고값은 1, 최저값은 0으로 정확도와 재현율을 계산에 포함하기 때문에 정확도 측정치보다는 항상 낮다

분류기 모델을 비교할때는 f1점수의 가중평균을 사용하는것이 좋다.

### 지원점수

지원점수는 데이터 셋에서 클래스의 실제 발생 횟수이다.


---
## 17.임계값 조정

2개의 클래스에서 처음 10개의 예측확률을 출력한다.

```python
y_pred_prob = logreg.predict_proba(X_test)[0:10]
y_pred_prob
```
```
array([[0.91382428, 0.08617572],
       [0.83565645, 0.16434355],
       [0.82033915, 0.17966085],
       [0.99025322, 0.00974678],
       [0.95726711, 0.04273289],
       [0.97993908, 0.02006092],
       [0.17833011, 0.82166989],
       [0.23480918, 0.76519082],
       [0.90048436, 0.09951564],
       [0.85485267, 0.14514733]])
```

### 관측결과
 * 각 행에서 숫자는 1로 합산된다
 * 0과 1의 두 클래스에 해당되는 2개의 열이 존재
 * 클래스 0 - 내일 강수 예상 X
 * 클래스 1 - 내일 강수 예상 O
 * 예측 확률의 중요성- 비가 올 확률에 따라 관측값의 순위를 매길 수 있다.
 * 예츨 프로바 과정 - 확률 예측 후 가장 높은 확률 클래스 선택
 * 분류 임계값 수준 - 0.5정도로 확률이 0.5 초과하면 비가 올 확률을, 0 미만이면 비가 내리지 않을 확률 예측


```python
y_pred_prob_df = pd.DataFrame(data=y_pred_prob, columns=['Prob of - No rain tomorrow (0)', 'Prob of - Rain tomorrow (1)'])

y_pred_prob_df
```
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Prob of - No rain tomorrow (0)</th>
      <th>Prob of - Rain tomorrow (1)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.913824</td>
      <td>0.086176</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.835656</td>
      <td>0.164344</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.820339</td>
      <td>0.179661</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.990253</td>
      <td>0.009747</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.957267</td>
      <td>0.042733</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.979939</td>
      <td>0.020061</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0.178330</td>
      <td>0.821670</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0.234809</td>
      <td>0.765191</td>
    </tr>
    <tr>
      <th>8</th>
      <td>0.900484</td>
      <td>0.099516</td>
    </tr>
    <tr>
      <th>9</th>
      <td>0.854853</td>
      <td>0.145147</td>
    </tr>
  </tbody>
</table>


클래스 1 - 비가 올 확률에 대한 예측 확률

```python
logreg.predict_proba(X_test)[0:10, 1]
```
```
array([0.08617572, 0.16434355, 0.17966085, 0.00974678, 0.04273289,
       0.02006092, 0.82166989, 0.76519082, 0.09951564, 0.14514733])
```
```python
y_pred1 = logreg.predict_proba(X_test)[:, 1]
plt.rcParams['font.size'] = 12


# plot histogram with 10 bins
plt.hist(y_pred1, bins = 10)


# set the title of predicted probabilities
plt.title('Histogram of predicted probabilities of rain')


# set the x-axis limit
plt.xlim(0,1)


# set the title
plt.xlabel('Predicted probabilities of rain')
plt.ylabel('Frequency')

```

Text(0, 0.5, 'Frequency')


<img src = "https://raw.githubusercontent.com/theRepetition/therepetition.github.io/master/img/output_229_1.png">

### 관측결과

* 히스토그램이 매우 양으로 치우쳐 있음.
* 첫번째 열은 확률이 0에서 1 사이인 관측값이 약 15000개임을 알려줌
* 확률이 0.5를 초과하는 소수의 관측값 존재
* 이 소수의 관측은 내일 비가 올 것이라 예측하지만
* 대부분의 관측은 비가 오지 않을거라 예측

### 임계치 낮추기

```python
from sklearn.preprocessing import binarize

for i in range(1,5):
    
    cm1=0
    
    y_pred1 = logreg.predict_proba(X_test)[:,1]
    
    y_pred1 = y_pred1.reshape(-1,1)
    
    y_pred2 = binarize(y_pred1, i/10)
    
    y_pred2 = np.where(y_pred2 == 1, 'Yes', 'No')
    
    cm1 = confusion_matrix(y_test, y_pred2)
        
    print ('With',i/10,'threshold the Confusion Matrix is ','\n\n',cm1,'\n\n',
           
            'with',cm1[0,0]+cm1[1,1],'correct predictions, ', '\n\n', 
           
            cm1[0,1],'Type I errors( False Positives), ','\n\n',
           
            cm1[1,0],'Type II errors( False Negatives), ','\n\n',
           
           'Accuracy score: ', (accuracy_score(y_test, y_pred2)), '\n\n',
           
           'Sensitivity: ',cm1[1,1]/(float(cm1[1,1]+cm1[1,0])), '\n\n',
           
           'Specificity: ',cm1[0,0]/(float(cm1[0,0]+cm1[0,1])),'\n\n',
          
            '====================================================', '\n\n')
```
```
With 0.1 threshold the Confusion Matrix is  

 [[12726  9341]
 [  547  5825]] 

 with 18551 correct predictions,  

 9341 Type I errors( False Positives),  

 547 Type II errors( False Negatives),  

 Accuracy score:  0.6523084496641935 

 Sensitivity:  0.9141556811048337 

 Specificity:  0.5766982371867494 

 ==================================================== 


With 0.2 threshold the Confusion Matrix is  

 [[17066  5001]
 [ 1234  5138]] 

 with 22204 correct predictions,  

 5001 Type I errors( False Positives),  

 1234 Type II errors( False Negatives),  

 Accuracy score:  0.7807588171173389 

 Sensitivity:  0.8063402385436284 

 Specificity:  0.7733720034440568 

 ==================================================== 


With 0.3 threshold the Confusion Matrix is  

 [[19080  2987]
 [ 1872  4500]] 

 with 23580 correct predictions,  

 2987 Type I errors( False Positives),  

 1872 Type II errors( False Negatives),  

 Accuracy score:  0.8291430781673055 

 Sensitivity:  0.7062146892655368 

 Specificity:  0.8646395069560883 

 ==================================================== 


With 0.4 threshold the Confusion Matrix is  

 [[20191  1876]
 [ 2517  3855]] 

 with 24046 correct predictions,  

 1876 Type I errors( False Positives),  

 2517 Type II errors( False Negatives),  

 Accuracy score:  0.845529027040332 

 Sensitivity:  0.6049905838041432 

 Specificity:  0.9149861784565188 

 ==================================================== 
```

* 이진 문제에서는 기본적으로 0.5의 임계값이 사용되어 예측확률을 클래스 예측으로 변환
* 임계값을 조정하여 재현율 또는 정밀도를 높일 수 있다
* 정밀도와 재현율은 반비례 관계이다
* 임계값 구치를 높이면 정확도가 높아짐
* 임계값 수준 조정을 모델 구축 과정의 마지막 단계로 수행해야됨



---
## 18.ROC-AUC

분류 모델성능을 시각적으로 측정하는 방법에는 ROC 곡선도 존재한다.
ROC 곡선은 다양한 분류 임계값 수준에서 분류 모델의 성능을 보여준다.

```python

from sklearn.metrics import roc_curve

fpr, tpr, thresholds = roc_curve(y_test, y_pred1, pos_label = 'Yes')

plt.figure(figsize=(6,4))

plt.plot(fpr, tpr, linewidth=2)

plt.plot([0,1], [0,1], 'k--' )

plt.rcParams['font.size'] = 12

plt.title('ROC curve for RainTomorrow classifier')

plt.xlabel('False Positive Rate (1 - Specificity)')

plt.ylabel('True Positive Rate (Sensitivity)')

plt.show()
```
<img src= "https://raw.githubusercontent.com/theRepetition/therepetition.github.io/master/img/output_235_0.png">

### ROC-AUC
ROC-AUC는 분류기 성능을 비교하는 기법으로 곡선 아래 면적을 측정한다.

완벽한 분류기는 1, 무작위 분류기는 0.5로 수렴한다.

```python

from sklearn.metrics import roc_auc_score

ROC_AUC = roc_auc_score(y_test, y_pred1)

print('ROC AUC : {:.4f}'.format(ROC_AUC))
```
> ROC AUC : 0.8729

1에 가까운 수치이기 때문에 이 분류기는 잘 작동한다.

---
## 19.k폴드 교차 검증

```python
from sklearn.model_selection import cross_val_score
scores = cross_val_score(logreg, X_train, y_train, cv = 5, scoring='accuracy')
print('Cross-validation scores:{}'.format(scores)
```
> Cross-validation scores:[0.84686387 0.84624852 0.84633642 0.84963298 0.84773626]

교차 검증 정확도에서 평균을 계산 하여 요약할 수 있다.

```python
print('Average cross-validation score: {:.4f}'.format(scores.mean()))
```
> Average cross-validation score: 0.8474

오리지널 모델 점수가 0.8476으로 교차 검증이 성능 향상으로 이어지지는 않는다.


---
## 20.그리드탐색을 이용한 하이퍼파라미터

```python
parameters = [{'penalty':['l1','l2']}, 
              {'C':[1, 10, 100, 1000]}]



grid_search = GridSearchCV(estimator = logreg,  
                           param_grid = parameters,
                           scoring = 'accuracy',
                           cv = 5,
                           verbose=0)

grid_search.fit(X_train, y_train)
```
```
GridSearchCV(cv=5, error_score='raise-deprecating',
             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,
                                          fit_intercept=True,
                                          intercept_scaling=1, l1_ratio=None,
                                          max_iter=100, multi_class='warn',
                                          n_jobs=None, penalty='l2',
                                          random_state=0, solver='liblinear',
                                          tol=0.0001, verbose=0,
                                          warm_start=False),
             iid='warn', n_jobs=None,
             param_grid=[{'penalty': ['l1', 'l2']}, {'C': [1, 10, 100, 1000]}],
             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,
             scoring='accuracy', verbose=0)
```
```python
print('GridSearch CV best score : {:.4f}\n\n'.format(grid_search.best_score_))
print('Parameters that give the best results :','\n\n', (grid_search.best_params_))
print('\n\nEstimator that was chosen by the search :','\n\n', (grid_search.best_estimator_))
```
```
GridSearch CV best score : 0.8474


Parameters that give the best results : 

 {'penalty': 'l1'}


Estimator that was chosen by the search : 

 LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='warn', n_jobs=None, penalty='l1',
                   random_state=0, solver='liblinear', tol=0.0001, verbose=0,
                   warm_start=False)
```
```python
print('GridSearch CV score on test set: {0:0.4f}'.format(grid_search.score(X_test, y_test)))
```
> GridSearch CV score on test set: 0.8507

원래 모델 테스트의 정확도에 비해 그리드 탐색 정확도는 살짝 올라갔다.


---
## 21.결과 및 결론

* 로지스틱 회귀 모델의 정확도는 0.8501로 상당히 정확하다
* 이 모델에는 오버핏의 징후가 없다
* C값을 높이면 테스트 셋의 정확도가 높아지기 때문에 복잡한 모델이 더 성능이 좋을것이다
* 임계치를 높이면 정확도가 올라간다
* 원래 모델에 비해 RFECV 정확도 점수는 0.8500 으로 비슷하지만 조금 낮다
* 원래 모델에서 FP=1175,FP1=1174이며, FN=3087, FN1=3091로 오류 탐지가 거의 동일하다
* 원래 모델의 0.8476에 비해 교차검증은 0.8474로 교차 검증은 성능향상에 도움이 되지 않는다
* 원래 모델의 정확도는 0.8501에 비해 그리드탐색의 정확도는 0.8507로 성능향상에 도움이 된다.


---
